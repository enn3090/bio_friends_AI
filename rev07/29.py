# 29.py (SyntaxError ìˆ˜ì • ì™„ë£Œ)

from __future__ import annotations

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import List, Dict, Any
from typing_extensions import TypedDict
from datetime import datetime
import json
import os
import re
import traceback

# LangGraph / LangChain
from langgraph.graph import StateGraph, START, END
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import (
    AnyMessage, SystemMessage, HumanMessage, AIMessage, BaseMessage
)
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ì‚¬ìš©ì ëª¨ë“ˆ (ì´ íŒŒì¼ë“¤ì´ rev07 í´ë” ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
from utils import save_state, get_outline, save_outline
from models import Task
from tools import retrieve

# GUI
import gradio as gr


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ë¡œ/íŒŒì¼ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

filename = os.path.basename(__file__)
absolute_path = os.path.abspath(__file__)
current_path = os.path.dirname(absolute_path)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM ì´ˆê¸°í™” (Ollama + DeepSeek-R1)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

llm = ChatOllama(
    model="deepseek-r1:latest",
    temperature=0.7,
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class State(TypedDict):
    messages: List[AnyMessage | str]
    task_history: List[Task]
    references: Dict[str, Any]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON ìœ í‹¸: LLM ì¶œë ¥ â†’ ì•ˆì „ íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_json_block(text: str) -> Dict[str, Any]:
    m = re.search(r"```json\s*(\{.*?\})\s*```", text, flags=re.S | re.I)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass

    stack = 0
    start_idx = -1
    for i, ch in enumerate(text):
        if ch == "{":
            if stack == 0:
                start_idx = i
            stack += 1
        elif ch == "}":
            stack -= 1
            if stack == 0 and start_idx != -1:
                candidate = text[start_idx : i + 1]
                try:
                    return json.loads(candidate)
                except Exception:
                    start_idx = -1
    return {}


def to_task(obj: Dict[str, Any]) -> Task:
    agent = str(obj.get("agent", "")).strip() or "communicator"
    description = str(obj.get("description", "")).strip() or "ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ í†µí•´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ íŒŒì•…í•œë‹¤"
    done = bool(obj.get("done", False))
    done_at = str(obj.get("done_at", ""))

    return Task(agent=agent, description=description, done=done, done_at=done_at)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Supervisor ì—ì´ì „íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def supervisor(state: State):
    print("\n\n============ SUPERVISOR ============")

    supervisor_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” AI íŒ€ì˜ supervisorë¡œì„œ AI íŒ€ì˜ ì‘ì—…ì„ ê´€ë¦¬í•˜ê³  ì§€ë„í•œë‹¤.
        ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì±…ì„ ì¨ì•¼ í•œë‹¤ëŠ” ìµœì¢… ëª©í‘œë¥¼ ì—¼ë‘ì— ë‘ê³ ,
        í˜„ì¬ í•´ì•¼í•  ì¼ê³¼ ì‚¬ìš©í•  agentë¥¼ ê²°ì •í•œë‹¤.

        ì‚¬ìš© ê°€ëŠ¥í•œ agent:
        - content_strategist: ìš”êµ¬ì‚¬í•­ì´ ëª…í™•í•  ë•Œ. ì½˜í…ì¸  ì „ëµ/ëª©ì°¨(outline) ì‘ì„±Â·ìˆ˜ì •
        - communicator: íŒë‹¨ì´ ì„œì§€ ì•Šê±°ë‚˜ ì‚¬ìš©ì í”¼ë“œë°± í•„ìš”í•  ë•Œ. ì§„í–‰ ë³´ê³  ë° ì§€ì‹œ ìš”ì²­
        - vector_search_agent: ë²¡í„° DB ê²€ìƒ‰ìœ¼ë¡œ ëª©ì°¨ì— í•„ìš”í•œ ë ˆí¼ëŸ°ìŠ¤/ì•„ì´ë””ì–´ ìˆ˜ì§‘

        ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ë¼.
        ------------------------------------------
        previous_outline:
        {outline}
        ------------------------------------------
        messages:
        {messages}
        ------------------------------------------

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì´ JSONë§Œ ì¶œë ¥í•˜ë¼):
        ```json
        {{
            "agent": "content_strategist" | "communicator" | "vector_search_agent",
            "description": "ê°„ë‹¨í•˜ê³  ëª…í™•í•œ í•  ì¼ ì„¤ëª…",
            "done": false,
            "done_at": ""
        }}
        ```
        """
    )

    chain = supervisor_system_prompt | llm | StrOutputParser()

    messages = state.get("messages", [])
    inputs = {
        "messages": messages,
        "outline": get_outline(current_path),
    }

    raw = chain.invoke(inputs)
    data = extract_json_block(raw)
    task = to_task(data)

    task_history = state.get("task_history", [])
    task_history.append(task)

    supervisor_message = AIMessage(f"[Supervisor] {task}")
    messages.append(supervisor_message)
    print(supervisor_message.content)

    return {"messages": messages, "task_history": task_history, "references": state.get("references", {"queries": [], "docs": []})}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¼ìš°í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def supervisor_router(state: State):
    task = state["task_history"][-1]
    return task.agent


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Vector Search Agent
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def vector_search_agent(state: State):
    print("\n\n============ VECTOR SEARCH AGENT ============")

    tasks = state.get("task_history", [])
    task = tasks[-1]
    if task.agent != "vector_search_agent":
        raise ValueError(f"Vector Search Agentê°€ ì•„ë‹Œ agentê°€ Vector Search Agentë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task}")

    vector_search_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ëª©ì°¨(outline) ì‘ì„±/ê°œì„ ì— í•„ìš”í•œ ì •ë³´ë¥¼ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì•„ë‚´ëŠ” Agentë‹¤.
        ë‹¤ìŒ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ì§ˆì˜(query) í›„ë³´ë¥¼ 3~8ê°œ ìƒì„±í•˜ë¼.
        - ê²€ìƒ‰ ëª©ì (ë¯¸ì…˜): {mission}
        - ê³¼ê±° ê²€ìƒ‰ ë‚´ìš©(ì¤‘ë³µ í”¼í•˜ê¸°):
          {references}
        - ìµœê·¼ ëŒ€í™”:
          {messages}
        - í˜„ì¬ ëª©ì°¨(ìˆë‹¤ë©´ ë³´ì™„ì  ê³ ë ¤):
          {outline}

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì´ JSONë§Œ ì¶œë ¥í•˜ë¼):
        ```json
        {{
            "queries": ["ì§§ê³  êµ¬ì²´ì ì¸ í•œê¸€/ì˜ë¬¸ ì§ˆì˜", "...", "..."],
            "notes": "ì§ˆì˜ ì˜ë„/ë³´ì™„ í¬ì¸íŠ¸(ì„ íƒ)"
        }}
        ```
        """
    )

    references = state.get("references", {"queries": [], "docs": []})
    messages = state["messages"]
    outline = get_outline(current_path)

    inputs = {
        "mission": task.description,
        "references": references,
        "messages": messages,
        "outline": outline,
    }

    chain = vector_search_system_prompt | llm | StrOutputParser()
    raw = chain.invoke(inputs)
    data = extract_json_block(raw)

    new_queries: List[str] = [q for q in data.get("queries", []) if isinstance(q, str)]
    if not new_queries:
        new_queries = [task.description]

    for query in new_queries:
        try:
            print("Query â†’", query)
            docs = retrieve({"query": query})
            references.setdefault("queries", []).append(query)
            references.setdefault("docs", []).extend(docs)
        except Exception as e:
            print(f"[retrieve ì—ëŸ¬] {e}")

    unique_docs = []
    seen = set()
    for doc in references.get("docs", []):
        content = getattr(doc, "page_content", None)
        if content and content not in seen:
            seen.add(content)
            unique_docs.append(doc)
    references["docs"] = unique_docs

    print('Queries:--------------------------')
    for q in references.get("queries", []):
        print(q)
    print('References:--------------------------')
    for doc in references.get("docs", [])[:10]:
        preview = getattr(doc, "page_content", "")[:120].replace("\n", " ")
        print(preview)
        print('--------------------------')

    tasks[-1].done = True
    tasks[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    new_task = Task(
        agent="communicator",
        done=False,
        description="AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ê³ , ì‚¬ìš©ìì˜ ì˜ê²¬ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤",
        done_at=""
    )
    tasks.append(new_task)

    msg_str = f"[VECTOR SEARCH AGENT] ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ì™„ë£Œ: {new_queries}"
    message = AIMessage(msg_str)
    messages.append(message)
    print(msg_str)

    return {
        "messages": messages,
        "task_history": tasks,
        "references": references
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì½˜í…ì¸  ì „ëµê°€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def content_strategist(state: State):
    print("\n\n============ CONTENT STRATEGIST ============\n")

    content_strategist_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ì±…ì„ ì“°ëŠ” AIíŒ€ì˜ ì½˜í…ì¸  ì „ëµê°€(Content Strategist)ë‹¤.
        ì´ì „ ëŒ€í™”ì™€ ê¸°ì¡´ ëª©ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬,
        ì±…ì˜ ì„¸ë¶€ ëª©ì°¨ë¥¼ ì‘ì„±í•˜ê±°ë‚˜(ì—†ìœ¼ë©´ ìƒì„±) ê¸°ì¡´ ëª©ì°¨ë¥¼ ê°œì„ í•œë‹¤.

        ì¶œë ¥ì€ 'ìµœì¢… ëª©ì°¨ í…ìŠ¤íŠ¸'ë§Œ ì‚°ì¶œí•˜ë¼. ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì œì™¸í•œë‹¤.
        --------------------------------
        ì§€ë‚œ ëª©ì°¨:
        {outline}
        --------------------------------
        ì´ì „ ëŒ€í™” ë‚´ìš©:
        {messages}
        """
    )

    chain = content_strategist_system_prompt | llm | StrOutputParser()

    messages = state["messages"]
    outline = get_outline(current_path)
    inputs = {"messages": messages, "outline": outline}

    gathered = ""
    for chunk in chain.stream(inputs):
        gathered += chunk
        print(chunk, end="")
    print()

    save_outline(current_path, gathered)

    content_strategist_message = "[Content Strategist] ëª©ì°¨ ì‘ì„± ì™„ë£Œ"
    messages.append(AIMessage(content=content_strategist_message))
    task_history = state.get("task_history", [])
    if task_history[-1].agent != "content_strategist":
        raise ValueError(f"Content Strategistê°€ ì•„ë‹Œ agentê°€ ëª©ì°¨ ì‘ì„±ì„ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task_history[-1]}")
    task_history[-1].done = True
    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    new_task = Task(
        agent="communicator",
        done=False,
        description="AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ê³ , ì‚¬ìš©ìì˜ ì˜ê²¬ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤",
        done_at=""
    )
    task_history.append(new_task)

    print(new_task)

    return {
        "messages": messages,
        "task_history": task_history,
        "references": state.get("references", {"queries": [], "docs": []}),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì»¤ë®¤ë‹ˆì¼€ì´í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def communicator(state: State):
    print("\n\n============ COMMUNICATOR ============\n")

    communicator_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ì±…ì„ ì“°ëŠ” AIíŒ€ì˜ ì»¤ë®¤ë‹ˆì¼€ì´í„°ë‹¤.
        AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ê°„ê²°íˆ ë³´ê³ í•˜ê³ , ë‹¤ìŒ ì§€ì‹œë¥¼ ë°›ëŠ”ë‹¤.
        ì‚¬ìš©ìëŠ” ì´ë¯¸ outline(ëª©ì°¨)ì„ ë³´ê³  ìˆë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ ëª©ì°¨ ì›ë¬¸ì„ ë‹¤ì‹œ ì¶œë ¥í•  í•„ìš”ëŠ” ì—†ë‹¤.

        ì°¸ê³ (í‘œì‹œ ê¸ˆì§€):
        outline: {outline}
        --------------------------------
        messages: {messages}
        """
    )

    system_chain = communicator_system_prompt | llm

    messages = state["messages"]
    inputs = {
        "messages": messages,
        "outline": get_outline(current_path),
    }

    print("\nAI\t: ", end="")
    gathered: BaseMessage | None = None
    for chunk in system_chain.stream(inputs):
        print(chunk.content, end="")
        if gathered is None:
            gathered = chunk
        else:
            gathered += chunk
    print()

    if gathered is None:
        gathered = AIMessage("ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    messages.append(gathered)

    task_history = state.get("task_history", [])
    if task_history[-1].agent != "communicator":
        raise ValueError(f"Communicatorê°€ ì•„ë‹Œ agentê°€ ëŒ€í™”ë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task_history[-1]}")
    task_history[-1].done = True
    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    return {
        "messages": messages,
        "task_history": task_history,
        "references": state.get("references", {"queries": [], "docs": []}),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangGraph ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

graph_builder = StateGraph(State)

graph_builder.add_node("supervisor", supervisor)
graph_builder.add_node("communicator", communicator)
graph_builder.add_node("content_strategist", content_strategist)
graph_builder.add_node("vector_search_agent", vector_search_agent)

graph_builder.add_edge(START, "supervisor")
graph_builder.add_conditional_edges(
    "supervisor",
    supervisor_router,
    {
        "content_strategist": "content_strategist",
        "communicator": "communicator",
        "vector_search_agent": "vector_search_agent",
    },
)
graph_builder.add_edge("content_strategist", "communicator")
graph_builder.add_edge("vector_search_agent", "communicator")
graph_builder.add_edge("communicator", END)

graph = graph_builder.compile()

try:
    graph.get_graph().draw_mermaid_png(output_file_path=absolute_path.replace('.py', '.png'))
except Exception:
    pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_state() -> State:
    return State(
        messages=[
            SystemMessage(
                content=f"""
                ë„ˆí¬ AIë“¤ì€ ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ì±…ì„ ì“°ëŠ” ì‘ê°€íŒ€ì´ë‹¤.
                ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ëŒ€í™”í•˜ë¼.

                í˜„ì¬ì‹œê°ì€ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ì´ë‹¤.
                """
            )
        ],
        task_history=[],
        references={"queries": [], "docs": []},
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gradio GUI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_chat(messages: List[BaseMessage | str]) -> str:
    lines = []
    for msg in messages:
        role = "SYS"
        content = ""
        if isinstance(msg, SystemMessage):
            role = "SYSTEM"
            content = msg.content
        elif isinstance(msg, HumanMessage):
            role = "USER"
            content = msg.content
        elif isinstance(msg, AIMessage):
            role = "AI"
            content = msg.content
        elif isinstance(msg, str):
            role = "TEXT"
            content = msg
        else:
            role = msg.__class__.__name__.upper()
            content = getattr(msg, "content", str(msg))
        lines.append(f"**{role}:** {content}")
    return "\n\n".join(lines)


def render_references(refs: Dict[str, Any]) -> str:
    if not refs:
        return "(ì°¸ì¡° ì—†ìŒ)"
    queries = refs.get("queries", [])
    docs = refs.get("docs", [])
    lines = []
    if queries:
        lines.append("### ğŸ” ìµœê·¼ ê²€ìƒ‰ ì§ˆì˜")
        for i, q in enumerate(queries[-10:], 1):
            lines.append(f"{i}. {q}")
    if docs:
        lines.append("\n### ğŸ“„ ì°¸ì¡° ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 8ê°œ)")
        for i, d in enumerate(docs[:8], 1):
            preview = getattr(d, "page_content", "")
            meta = getattr(d, "metadata", {})
            src = meta.get("source") or meta.get("url") or ""
            # âœ…âœ…âœ… ì´ ë¶€ë¶„ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤ âœ…âœ…âœ…
            clean_preview = preview[:160].replace('\n', ' ')
            line = f"**{i}.** {clean_preview}" + (f"\nâ€” _{src}_" if src else "")
            lines.append(line)
    return "\n\n".join(lines) or "(ì°¸ì¡° ì—†ìŒ)"


def ui_on_send(user_text: str, state: State):
    try:
        if state is None:
            state = init_state()

        if user_text.strip():
            state["messages"].append(HumanMessage(user_text.strip()))
            new_state = graph.invoke(state)

            save_state(current_path, new_state)

            chat_md = render_chat(new_state["messages"])
            outline_text = get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)"
            refs_md = render_references(new_state.get("references"))
            return chat_md, outline_text, refs_md, new_state
        else:
            chat_md = render_chat(state["messages"])
            outline_text = get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)"
            refs_md = render_references(state.get("references"))
            return chat_md, outline_text, refs_md, state
    except Exception as e:
        tb = traceback.format_exc()
        err_msg = f"[ì—ëŸ¬] {e}\n\n{tb}"
        chat_md = render_chat(state["messages"] if state else [])
        return chat_md + "\n\n" + err_msg, get_outline(current_path), "(ì°¸ì¡° ì—†ìŒ)", state


def ui_on_reset():
    state = init_state()
    return render_chat(state["messages"]), get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)", "(ì°¸ì¡° ì—†ìŒ)", state


def launch_gradio():
    with gr.Blocks(title="AI Book Team (Ollama + DeepSeek-R1)") as demo:
        gr.Markdown("## âœï¸ AI Book Team (Local Ollama Â· DeepSeek-R1)\nì˜¤ë¥¸ìª½ì— ìµœì‹  ëª©ì°¨ì™€ ê²€ìƒ‰ ë ˆí¼ëŸ°ìŠ¤ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        with gr.Row():
            with gr.Column(scale=2):
                chat_md = gr.Markdown(value="")
                user_in = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì˜ˆ) 'AIë¡œ ì±…ì„ ì“°ê³  ì‹¶ì–´ìš”. ì£¼ì œëŠ” ...'")
                with gr.Row():
                    send_btn = gr.Button("ë³´ë‚´ê¸°", variant="primary")
                    reset_btn = gr.Button("ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
            with gr.Column(scale=1):
                outline_md = gr.Markdown(label="í˜„ì¬ ëª©ì°¨", value="(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)")
                refs_md = gr.Markdown(label="ê²€ìƒ‰ ë ˆí¼ëŸ°ìŠ¤", value="(ì°¸ì¡° ì—†ìŒ)")

        state_box = gr.State(init_state())

        send_btn.click(
            fn=ui_on_send,
            inputs=[user_in, state_box],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )
        user_in.submit(
            fn=ui_on_send,
            inputs=[user_in, state_box],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )
        reset_btn.click(
            fn=ui_on_reset,
            inputs=[],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )

    demo.launch()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    launch_gradio()