# ------------------------------------------------------------
# OpenAI API â†’ Ollama(DeepSeek-R1) ë³€í™˜ + Gradio ìš”ì•½ ì•±
# ------------------------------------------------------------
# âœ… ê¸°ëŠ¥
#   - PDFì—ì„œ í—¤ë”/í‘¸í„° ì˜ì—­ ì œê±° í›„ ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)
#   - ê¸´ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ìˆœì°¨ ìš”ì•½ í›„ ìµœì¢… í†µí•© ìš”ì•½ (Ollama deepseek-r1)
#   - Gradio ê¸°ë°˜ GUI: PDF ì—…ë¡œë“œ â†’ ì˜µì…˜ ì§€ì • â†’ ìš”ì•½/í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
#
# âš™ï¸ ì‚¬ì „ ì¤€ë¹„
#   pip install gradio ollama pymupdf
#   (pymupdfëŠ” ì½”ë“œì—ì„œ fitzë¡œ import)
#   Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ì¤€ë¹„:  
#     - https://ollama.com/download  
#     - ëª¨ë¸: `ollama pull deepseek-r1`
# ------------------------------------------------------------

import os
import io
import tempfile
from typing import List

import gradio as gr
import ollama
import fitz  # PyMuPDF

# -------------------------
# êµ¬ì„±ê°’
# -------------------------
MODEL_NAME = "deepseek-r1"  # ë¡œì»¬ì— ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
DEFAULT_TEMPERATURE = 0.1    # ìš”ì•½ì€ ë³´ìˆ˜ì ìœ¼ë¡œ

# -------------------------
# PDF â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í—¤ë”/í‘¸í„° ì œê±°)
# -------------------------

def pdf_to_text(pdf_path: str, header_height: float = 80, footer_height: float = 80) -> str:
    """PDFì—ì„œ í—¤ë”/í‘¸í„° ì˜ì—­ì„ ì˜ë¼ë‚´ê³  ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì´ì–´ë¶™ì—¬ ë°˜í™˜.
    - header_height, footer_height: í¬ì¸íŠ¸ ë‹¨ìœ„(px ìœ ì‚¬). í˜ì´ì§€ ë†’ì´ì— ë§ì¶° ì ì ˆíˆ ì¡°ì •.
    """
    doc = fitz.open(pdf_path)
    chunks = []

    for page_idx, page in enumerate(doc, start=1):
        rect = page.rect  # (x0, y0, x1, y1)
        # ë³¸ë¬¸ ì˜ì—­ë§Œ clipí•´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        body = page.get_text(
            "text",
            clip=(0, header_height, rect.width, rect.height - footer_height)
        )
        chunks.append(f"\n[í˜ì´ì§€ {page_idx}]\n{body.strip()}\n" + ("-" * 40))

    return "\n".join(chunks)


# -------------------------
# í…ìŠ¤íŠ¸ ì²­í¬ ë‚˜ëˆ„ê¸°
# -------------------------

def chunk_text(text: str, max_chars: int = 6000) -> List[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ max_chars ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í• .
    (ê°„ë‹¨í•œ ë¬¸ì ê¸¸ì´ ê¸°ì¤€. ëª¨ë¸/í™˜ê²½ì— ë”°ë¼ ì¡°ì ˆ)
    """
    paragraphs = text.split("\n\n")
    chunks, buf = [], []
    size = 0
    for p in paragraphs:
        p = p.strip()
        if not p:
            continue
        if size + len(p) + 2 > max_chars and buf:
            chunks.append("\n\n".join(buf))
            buf, size = [p], len(p)
        else:
            buf.append(p)
            size += len(p) + 2
    if buf:
        chunks.append("\n\n".join(buf))
    return chunks


# -------------------------
# Ollama í˜¸ì¶œ ìœ í‹¸
# -------------------------

def ollama_summarize(user_prompt: str, system_prompt: str, temperature: float = DEFAULT_TEMPERATURE) -> str:
    """Ollama chat APIë¡œ ìš”ì•½ ìƒì„±. system/user ë©”ì‹œì§€ ì‚¬ìš©."""
    resp = ollama.chat(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        options={"temperature": float(temperature)}
    )
    return resp["message"]["content"].strip()


# -------------------------
# ë¬¸ì„œ ìš”ì•½ íŒŒì´í”„ë¼ì¸ (ë¶„í•  â†’ ë¶€ë¶„ìš”ì•½ â†’ í†µí•©ìš”ì•½)
# -------------------------

def summarize_text(text: str, temperature: float = DEFAULT_TEMPERATURE) -> str:
    """ê¸´ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ  ë¶€ë¶„ ìš”ì•½í•˜ê³ , ë§ˆì§€ë§‰ì— í†µí•© ìš”ì•½."""
    # 1) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì ìš”êµ¬ì— ë§ì¶¤)
    system_prompt = (
        "ë„ˆëŠ” ë‹¤ìŒ ê¸€ì„ ìš”ì•½í•˜ëŠ” ë´‡ì´ë‹¤. ì €ìì˜ ë¬¸ì œ ì¸ì‹ê³¼ ì£¼ì¥, ì£¼ìš” ë‚´ìš©ì„ ì •í™•íˆ ìš”ì•½í•˜ë¼.\n"
        "ì¶œë ¥ í˜•ì‹:\n\n"
        "# ì œëª©\n\n"
        "## ì €ìì˜ ë¬¸ì œ ì¸ì‹ ë° ì£¼ì¥ (15ë¬¸ì¥ ì´ë‚´)\n\n"
        "## ì €ì ì†Œê°œ\n"
    )

    # 2) ë³¸ë¬¸ì´ ë§¤ìš° ê¸¸ë‹¤ë©´ ë©ì–´ë¦¬ë¡œ ìš”ì•½
    chunks = chunk_text(text, max_chars=6000)

    partials = []
    for i, ch in enumerate(chunks, start=1):
        user_prompt = (
            f"ì•„ë˜ëŠ” ë¬¸ì„œì˜ ì¼ë¶€(ì²­í¬ {i}/{len(chunks)})ì´ë‹¤. í•µì‹¬ ì£¼ì¥ê³¼ ê·¼ê±°ë¥¼ ë³´ì¡´í•˜ë©° ìš”ì•½í•˜ë¼.\n"
            f"ë¶„ëŸ‰: 7~12ë¬¸ì¥ ê¶Œì¥.\n\n=== ì²­í¬ ì‹œì‘ ===\n{ch}\n=== ì²­í¬ ë ==="
        )
        partial = ollama_summarize(user_prompt, system_prompt, temperature)
        partials.append(partial)

    if len(partials) == 1:
        return partials[0]

    # 3) ë¶€ë¶„ ìš”ì•½ë“¤ì„ í†µí•© ìš”ì•½
    merged_source = "\n\n".join(partials)
    merge_prompt = (
        "ë‹¤ìŒì€ ë¬¸ì„œì˜ ë¶€ë¶„ ìš”ì•½ë“¤ì„ ëª¨ì•„ ë‘” ê²ƒì´ë‹¤. ì¤‘ë³µì„ ì œê±°í•˜ê³ , ë…¼ë¦¬ì  íë¦„ì„ ì •ë¦¬í•˜ì—¬"
        " í•˜ë‚˜ì˜ ì™„ì„±ëœ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•˜ë¼. í‘œì œ/ì†Œì œëª© í˜•ì‹ì€ ì§€í‚¤ê³ , êµ¬ì²´ì  ìˆ˜ì¹˜/ì§€í‘œ/ì—°ë„ëŠ” ë³´ì¡´í•˜ë¼.\n\n"
        f"=== ë¶€ë¶„ ìš”ì•½ë“¤ ì‹œì‘ ===\n{merged_source}\n=== ë¶€ë¶„ ìš”ì•½ë“¤ ë ==="
    )
    final_summary = ollama_summarize(merge_prompt, system_prompt, temperature)
    return final_summary


# -------------------------
# Gradio ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# -------------------------

def process_pdf(pdf_file, header_h, footer_h, temperature):
    """PDF íŒŒì¼ì„ ë°›ì•„ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ìš”ì•½. ê²°ê³¼ í…ìŠ¤íŠ¸/ìš”ì•½, ë‹¤ìš´ë¡œë“œ íŒŒì¼ ë°˜í™˜."""
    if pdf_file is None:
        return gr.update(value=""), gr.update(value=""), None, None

    # 1) ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ ê²½ë¡œ í™•ë³´ (gradio íŒŒì¼ ê°ì²´ëŠ” temp ê²½ë¡œ í¬í•¨)
    pdf_path = pdf_file.name

    # 2) í…ìŠ¤íŠ¸ ì¶”ì¶œ
    extracted_text = pdf_to_text(pdf_path, header_height=header_h, footer_height=footer_h)

    # 3) ìš”ì•½
    summary = summarize_text(extracted_text, temperature=temperature)

    # 4) ë‹¤ìš´ë¡œë“œ íŒŒì¼ ì¤€ë¹„
    tmpdir = tempfile.mkdtemp(prefix="pdfsum_")
    base = os.path.splitext(os.path.basename(pdf_path))[0]

    txt_path = os.path.join(tmpdir, f"{base}_extracted.txt")
    sum_path = os.path.join(tmpdir, f"{base}_summary.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(extracted_text)
    with open(sum_path, "w", encoding="utf-8") as f:
        f.write(summary)

    return summary, extracted_text, txt_path, sum_path


# -------------------------
# Gradio UI êµ¬ì„±
# -------------------------
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸ“„ PDF ìš”ì•½ê¸° (Ollama DeepSeek-R1)
        - **í—¤ë”/í‘¸í„° ì œê±°** í›„ ë³¸ë¬¸ë§Œ ì¶”ì¶œí•´ì„œ ìš”ì•½í•©ë‹ˆë‹¤.
        - ëª¨ë¸: `deepseek-r1` (ë¡œì»¬ Ollama)
        - ê¸´ ë¬¸ì„œë„ **ì²­í¬ ìš”ì•½ â†’ í†µí•© ìš”ì•½**ìœ¼ë¡œ ì•ˆì • ì²˜ë¦¬
        """
    )

    with gr.Row():
        with gr.Column(scale=2):
            pdf_in = gr.File(label="PDF ì—…ë¡œë“œ", file_types=[".pdf"], type="filepath")
            header_h = gr.Number(value=80, label="í—¤ë” ë†’ì´(px)")
            footer_h = gr.Number(value=80, label="í‘¸í„° ë†’ì´(px)")
            temp_in = gr.Slider(0.0, 1.5, value=DEFAULT_TEMPERATURE, step=0.1, label="Temperature (ì°½ì˜ì„±)")
            run_btn = gr.Button("ìš”ì•½ ì‹¤í–‰", variant="primary")
        with gr.Column(scale=3):
            summary_out = gr.Textbox(label="ìµœì¢… ìš”ì•½", lines=18)
            text_out = gr.Textbox(label="ì¶”ì¶œ í…ìŠ¤íŠ¸(í—¤ë”/í‘¸í„° ì œê±°)", lines=18)
            with gr.Row():
                dl_text = gr.File(label="ì¶”ì¶œ í…ìŠ¤íŠ¸ íŒŒì¼")
                dl_sum = gr.File(label="ìš”ì•½ ê²°ê³¼ íŒŒì¼")

    run_btn.click(process_pdf, [pdf_in, header_h, footer_h, temp_in], [summary_out, text_out, dl_text, dl_sum])


# -------------------------
# ì‹¤í–‰ ì—”íŠ¸ë¦¬
# -------------------------
if __name__ == "__main__":
    # ê³µìœ  í•„ìš” ì‹œ: demo.launch(share=True)
    demo.launch()