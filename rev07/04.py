# ------------------------------------------------------------
# OpenAI API ì½”ë“œ â†’ Ollama + DeepSeek-R1 ë³€í™˜ ì˜ˆì œ
# ------------------------------------------------------------
# âœ… ì£¼ìš” ë³€ê²½ì :
#   1. OpenAI API Key ì‚¬ìš© ì œê±° â†’ ë¡œì»¬ì— ì„¤ì¹˜ëœ Ollama ëª¨ë¸ í™œìš©
#   2. ëª¨ë¸ëª…: "deepseek-r1" (ë¡œì»¬ í™˜ê²½ì— ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
#   3. ì¸í„°í˜ì´ìŠ¤: Gradioë¡œ ê°„ë‹¨í•œ ëŒ€í™” UI êµ¬í˜„
# ------------------------------------------------------------

import gradio as gr
import ollama  # Ollama ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install ollama)

# ------------------------------------------------------------
# ëª¨ë¸ê³¼ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------
def chat_with_model(user_input, history):
    """
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ DeepSeek-R1 ëª¨ë¸ì— ì „ë‹¬í•˜ê³ ,
    ì‘ë‹µì„ ë°›ì•„ì„œ ëŒ€í™” ê¸°ë¡(history)ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
    """

    # Ollama ëª¨ë¸ í˜¸ì¶œ
    response = ollama.chat(
        model="deepseek-r1",  # ë¡œì»¬ì— ì„¤ì¹˜ëœ DeepSeek-R1 ëª¨ë¸ ì‚¬ìš©
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ìœ ì¹˜ì› í•™ìƒì´ì•¼. ìœ ì¹˜ì›ìƒì²˜ëŸ¼ ë‹µë³€í•´ì¤˜."},
            *history,  # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ìœ ì§€
            {"role": "user", "content": user_input},
        ]
    )

    # ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    bot_message = response["message"]["content"]

    # Gradioê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ history ë°˜í™˜ í˜•ì‹ ë§ì¶”ê¸°
    history.append({"role": "user", "content": user_input})
    history.append({"role": "assistant", "content": bot_message})

    # Gradioì˜ Chatbot í˜•ì‹ì€ (ì§ˆë¬¸, ë‹µë³€) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    display_history = []
    for i in range(0, len(history), 2):
        if i + 1 < len(history):
            display_history.append((history[i]["content"], history[i+1]["content"]))

    return display_history, history


# ------------------------------------------------------------
# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•
# ------------------------------------------------------------
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ¤ DeepSeek-R1 ìœ ì¹˜ì›ìƒ ëª¨ë“œ ëŒ€í™”í•˜ê¸°")

    chatbot = gr.Chatbot()  # ëŒ€í™”ì°½
    state = gr.State([])    # ëŒ€í™” ê¸°ë¡ ì €ì¥ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)

    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

    # ì…ë ¥ì°½ì—ì„œ ì—”í„° â†’ ëª¨ë¸ ì‘ë‹µ ì‹¤í–‰
    txt.submit(chat_with_model, [txt, state], [chatbot, state])
    txt.submit(lambda: "", None, txt)  # ì…ë ¥ì°½ ì´ˆê¸°í™”

# ------------------------------------------------------------
# ì‹¤í–‰
# ------------------------------------------------------------
if __name__ == "__main__":
    demo.launch()
