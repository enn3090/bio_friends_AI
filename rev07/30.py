# 30.py (SyntaxError ìˆ˜ì • ì™„ë£Œ)

from __future__ import annotations

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import List, Dict, Any
from typing_extensions import TypedDict
from datetime import datetime
import json
import os
import re
import traceback

# LangGraph / LangChain
from langgraph.graph import StateGraph, START, END
# âœ… OpenAI â†’ Ollama ì „í™˜
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import (
    AnyMessage, SystemMessage, HumanMessage, AIMessage, BaseMessage
)
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ì‚¬ìš©ì ëª¨ë“ˆ (ê¸°ì¡´ ìœ ì§€)
from utils import save_state, get_outline, save_outline
from models import Task
from tools import retrieve, web_search, add_web_pages_json_to_chroma  # â† ê¸°ì¡´ ì‹œê·¸ë‹ˆì²˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©

# GUI
import gradio as gr


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ë¡œ/íŒŒì¼ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

filename = os.path.basename(__file__)
absolute_path = os.path.abspath(__file__)
current_path = os.path.dirname(absolute_path)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM ì´ˆê¸°í™” (Ollama + DeepSeek-R1)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
- OpenAIìš© ChatOpenAI â†’ ì˜¤í”ˆì†ŒìŠ¤ìš© ChatOllama
- DeepSeek-R1ì€ <think>â€¦</think> ì‚¬ê³ íë¦„ì„ ë‚´ë³´ë‚¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
  í”„ë¡¬í”„íŠ¸ì—ì„œ "ìµœì¢… ê²°ê³¼ëŠ” JSON/í…ìŠ¤íŠ¸ë§Œ"ì„ ê°•í•˜ê²Œ ì§€ì‹œí•˜ê³ 
  ì•„ë˜ extract_json_block()ìœ¼ë¡œ íŒŒì‹±ì„ ì•ˆì •í™”
"""
llm = ChatOllama(
    model="deepseek-r1:latest",  # ì„¤ì¹˜ëœ íƒœê·¸ì— ë§ê²Œ ì¡°ì • ê°€ëŠ¥ (ì˜ˆ: deepseek-r1:7b)
    temperature=0.7,
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class State(TypedDict):
    messages: List[AnyMessage | str]
    task_history: List[Task]
    references: Dict[str, Any]  # {"queries": List[str], "docs": List[Document-like]}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON ìœ í‹¸: LLM ì¶œë ¥ â†’ ì•ˆì „ íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_json_block(text: str) -> Dict[str, Any]:
    """
    DeepSeek-R1ì´ ì‚¬ê³ íë¦„ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
    ê°€ì¥ ê·¸ëŸ´ë“¯í•œ JSON ê°ì²´ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ.
    1) ```json ... ``` ìš°ì„ 
    2) ê· í˜• ì¡íŒ ì¤‘ê´„í˜¸ íƒìƒ‰ íœ´ë¦¬ìŠ¤í‹±
    ì‹¤íŒ¨ ì‹œ {} ë°˜í™˜
    """
    m = re.search(r"```json\s*(\{.*?\})\s*```", text, flags=re.S | re.I)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass

    stack = 0
    start_idx = -1
    for i, ch in enumerate(text):
        if ch == "{":
            if stack == 0:
                start_idx = i
            stack += 1
        elif ch == "}":
            stack -= 1
            if stack == 0 and start_idx != -1:
                candidate = text[start_idx : i + 1]
                try:
                    return json.loads(candidate)
                except Exception:
                    start_idx = -1
    return {}


def to_task(obj: Dict[str, Any]) -> Task:
    """
    JSON dict â†’ Task(Pydantic)ë¡œ ì—„ê²© ë³€í™˜.
    í•„ìˆ˜: agent, description
    ì„ íƒ: done, done_at
    """
    agent = str(obj.get("agent", "")).strip() or "communicator"
    description = str(obj.get("description", "")).strip() or "ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ í†µí•´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ íŒŒì•…í•œë‹¤"
    done = bool(obj.get("done", False))
    done_at = str(obj.get("done_at", ""))

    return Task(agent=agent, description=description, done=done, done_at=done_at)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Supervisor ì—ì´ì „íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def supervisor(state: State):
    print("\n\n============ SUPERVISOR ============")

    supervisor_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” AI íŒ€ì˜ supervisorë¡œì„œ AI íŒ€ì˜ ì‘ì—…ì„ ê´€ë¦¬í•˜ê³  ì§€ë„í•œë‹¤.
        ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì±…ì„ ì¨ì•¼ í•œë‹¤ëŠ” ìµœì¢… ëª©í‘œë¥¼ ì—¼ë‘ì— ë‘ê³ ,
        í˜„ì¬ í•´ì•¼í•  ì¼ê³¼ ì‚¬ìš©í•  agentë¥¼ ê²°ì •í•œë‹¤.

        ì‚¬ìš© ê°€ëŠ¥í•œ agent:
        - content_strategist: ìš”êµ¬ì‚¬í•­ì´ ëª…í™•í•  ë•Œ. ì½˜í…ì¸  ì „ëµ/ëª©ì°¨(outline) ì‘ì„±Â·ìˆ˜ì •
        - communicator: íŒë‹¨ì´ ì„œì§€ ì•Šê±°ë‚˜ ì‚¬ìš©ì í”¼ë“œë°± í•„ìš”í•  ë•Œ. ì§„í–‰ ë³´ê³  ë° ì§€ì‹œ ìš”ì²­
        - web_search_agent: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹ /ë°°ê²½ ì •ë³´ë¥¼ ìˆ˜ì§‘
        - vector_search_agent: ë²¡í„° DB ê²€ìƒ‰ìœ¼ë¡œ ë ˆí¼ëŸ°ìŠ¤/ì•„ì´ë””ì–´ ë³´ê°•

        ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ë¼.
        ------------------------------------------
        previous_outline:
        {outline}
        ------------------------------------------
        messages:
        {messages}
        ------------------------------------------

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì´ JSONë§Œ ì¶œë ¥í•˜ë¼):
        ```json
        {{
          "agent": "content_strategist" | "communicator" | "vector_search_agent" | "web_search_agent",
          "description": "ê°„ë‹¨í•˜ê³  ëª…í™•í•œ í•  ì¼ ì„¤ëª…",
          "done": false,
          "done_at": ""
        }}
        ```
        """
    )

    chain = supervisor_system_prompt | llm | StrOutputParser()

    messages = state.get("messages", [])
    inputs = {
        "messages": messages,
        "outline": get_outline(current_path),
    }

    raw = chain.invoke(inputs)
    data = extract_json_block(raw)
    task = to_task(data)

    task_history = state.get("task_history", [])
    task_history.append(task)

    supervisor_message = AIMessage(f"[Supervisor] {task}")
    messages.append(supervisor_message)
    print(supervisor_message.content)

    # references í‚¤ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´ì¥
    return {
        "messages": messages,
        "task_history": task_history,
        "references": state.get("references", {"queries": [], "docs": []}),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¼ìš°í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def supervisor_router(state: State):
    task = state["task_history"][-1]
    return task.agent



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Vector Search Agent (OpenAI í•¨ìˆ˜ â†’ JSON ê³„íš + íŒŒì´ì¬ ì§ì ‘ í˜¸ì¶œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def vector_search_agent(state: State):
    print("\n\n============ VECTOR SEARCH AGENT ============")

    tasks = state.get("task_history", [])
    task = tasks[-1]
    if task.agent != "vector_search_agent":
        raise ValueError(f"Vector Search Agentê°€ ì•„ë‹Œ agentê°€ Vector Search Agentë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task}")

    vector_search_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ëª©ì°¨(outline) ì‘ì„±/ê°œì„ ì— í•„ìš”í•œ ì •ë³´ë¥¼ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì•„ë‚´ëŠ” Agentë‹¤.
        ë‹¤ìŒ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ì§ˆì˜(query) í›„ë³´ë¥¼ 3~8ê°œ ìƒì„±í•˜ë¼.
        - ê²€ìƒ‰ ëª©ì (ë¯¸ì…˜): {mission}
        - ê³¼ê±° ê²€ìƒ‰ ë‚´ìš©(ì¤‘ë³µ í”¼í•˜ê¸°):
          {references}
        - ìµœê·¼ ëŒ€í™”:
          {messages}
        - í˜„ì¬ ëª©ì°¨(ìˆë‹¤ë©´ ë³´ì™„ì  ê³ ë ¤):
          {outline}

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì´ JSONë§Œ ì¶œë ¥í•˜ë¼):
        ```json
        {{
          "queries": ["ì§§ê³  êµ¬ì²´ì ì¸ í•œê¸€/ì˜ë¬¸ ì§ˆì˜", "...", "..."],
          "notes": "ì§ˆì˜ ì˜ë„/ë³´ì™„ í¬ì¸íŠ¸(ì„ íƒ)"
        }}
        ```
        """
    )

    references = state.get("references", {"queries": [], "docs": []})
    messages = state["messages"]
    outline = get_outline(current_path)

    inputs = {
        "mission": task.description,
        "references": references,
        "messages": messages,
        "outline": outline,
    }

    chain = vector_search_system_prompt | llm | StrOutputParser()
    raw = chain.invoke(inputs)
    data = extract_json_block(raw)

    new_queries: List[str] = [q for q in data.get("queries", []) if isinstance(q, str)]
    if not new_queries:
        # í´ë°±: ë¯¸ì…˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ í•œ ê°œì˜ ì§ˆì˜ë¡œ ì‚¬ìš©
        new_queries = [task.description]

    # ê²€ìƒ‰ ìˆ˜í–‰ ë° ê²°ê³¼ ëˆ„ì 
    for query in new_queries:
        try:
            print("Vector Query â†’", query)
            docs = retrieve({"query": query})  # â† ê¸°ì¡´ tools.retrieve ì‚¬ìš©
            references.setdefault("queries", []).append(query)
            references.setdefault("docs", []).extend(docs)
        except Exception as e:
            print(f"[retrieve ì—ëŸ¬] {e}")

    # ë¬¸ì„œ ì¤‘ë³µ ì œê±°(í˜ì´ì§€ ë‚´ìš© ê¸°ì¤€)
    unique_docs = []
    seen = set()
    for doc in references.get("docs", []):
        content = getattr(doc, "page_content", None)
        if content and content not in seen:
            seen.add(content)
            unique_docs.append(doc)
    references["docs"] = unique_docs

    # ë¡œê·¸ ì¶œë ¥
    print('Queries:--------------------------')
    for q in references.get("queries", []):
        print(q)
    print('References:--------------------------')
    for doc in references.get("docs", [])[:10]:  # ë„ˆë¬´ ê¸¸ë©´ ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
        preview = getattr(doc, "page_content", "")[:120].replace("\n", " ")
        print(preview)
        print('--------------------------')

    # task ì™„ë£Œ ì²˜ë¦¬ + ë‹¤ìŒ task: communicator
    tasks[-1].done = True
    tasks[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    new_task = Task(
        agent="communicator",
        done=False,
        description="AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ê³ , ì‚¬ìš©ìì˜ ì˜ê²¬ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤",
        done_at=""
    )
    tasks.append(new_task)

    # ë©”ì‹œì§€ ê¸°ë¡
    msg_str = f"[VECTOR SEARCH AGENT] ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ì™„ë£Œ: {new_queries}"
    message = AIMessage(msg_str)
    messages.append(message)
    print(msg_str)

    return {
        "messages": messages,
        "task_history": tasks,
        "references": references
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Web Search Agent (OpenAI ToolCalling â†’ JSON ê³„íš + íŒŒì´ì¬ ì§ì ‘ í˜¸ì¶œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def web_search_agent(state: State):
    print("\n\n============ WEB SEARCH AGENT ============")

    tasks = state.get("task_history", [])
    task = tasks[-1]

    if task.agent != "web_search_agent":
        raise ValueError(f"Web Search Agentê°€ ì•„ë‹Œ agentê°€ Web Search Agentë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task}")

    web_search_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ëª©ì°¨(outline) ì‘ì„±ì— í•„ìš”í•œ ìµœì‹ /ë°°ê²½ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” Agentë‹¤.
        í˜„ì¬ ë¶€ì¡±í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ë³µí•©ì ì¸ ì§ˆë¬¸ì€ ë‚˜ëˆ ì„œ 3~8ê°œì˜ ê²€ìƒ‰ ì§ˆì˜ë¥¼ ì œì•ˆí•˜ë¼.
        ê°€ëŠ¥í•œ í•œ ìµœì‹ ì„±ê³¼ ì‹ ë¢°ë„ë¥¼ ê³ ë ¤í•œ í‚¤ì›Œë”©ì„ ì‚¬ìš©í•˜ë¼.

        - ê²€ìƒ‰ ëª©ì : {mission}
        --------------------------------
        - ê³¼ê±° ê²€ìƒ‰ ë‚´ìš©(ì¤‘ë³µ í”¼í•˜ê¸°): {references}
        --------------------------------
        - ì´ì „ ëŒ€í™”: {messages}
        --------------------------------
        - í˜„ì¬ ëª©ì°¨: {outline}
        --------------------------------
        - í˜„ì¬ ì‹œê°: {current_time}

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì´ JSONë§Œ ì¶œë ¥í•˜ë¼):
        ```json
        {{
          "queries": ["ê²€ìƒ‰ì–´1", "ê²€ìƒ‰ì–´2", "..."],
          "notes": "ì¶œì²˜ ìš°ì„ ìˆœìœ„/ìˆ˜ì§‘ ê¸°ì¤€ ë“±(ì„ íƒ)"
        }}
        ```
        """
    )

    messages = state.get("messages", [])
    inputs = {
        "mission": task.description,
        "references": state.get("references", {"queries": [], "docs": []}),
        "messages": messages,
        "outline": get_outline(current_path),
        "current_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    }

    # LLMì´ JSON í˜•íƒœì˜ 'ê²€ìƒ‰ ê³„íš'ë§Œ ì¶œë ¥í•˜ë„ë¡ ìœ ë„
    chain = web_search_system_prompt | llm | StrOutputParser()
    raw = chain.invoke(inputs)
    data = extract_json_block(raw)

    queries: List[str] = [q for q in data.get("queries", []) if isinstance(q, str)]
    if not queries:
        # í´ë°±: ë¯¸ì…˜ ë¬¸ì¥ ì‚¬ìš©
        queries = [task.description]

    # ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰ ë° ìƒ‰ì¸
    executed_queries = []
    for q in queries:
        print('-------- web search --------', q)
        try:
            # tools.web_searchëŠ” (results, json_path) ë“±ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
            _, json_path = web_search.invoke({"query": q})
            print('json_path:', json_path)

            # ê²€ìƒ‰ ê²°ê³¼ JSONì„ Chromaì— ì¶”ê°€
            add_web_pages_json_to_chroma(json_path)
            executed_queries.append(q)
        except Exception as e:
            print(f"[web_search/add_to_chroma ì—ëŸ¬] {e}")

    # task ì™„ë£Œ
    tasks[-1].done = True
    tasks[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # ìƒˆë¡œìš´ task: Vector Search Agentë¡œ ì „í™˜ (ë°©ê¸ˆ ìƒ‰ì¸í•œ ë¬¸ì„œë“¤ í™œìš©)
    task_desc = "AIíŒ€ì´ ì“¸ ì±…ì˜ ì„¸ë¶€ ëª©ì°¨ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•œ ì •ë³´ë¥¼ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ë³´ê°•í•œë‹¤."
    if executed_queries:
        task_desc += f" ìƒˆë¡œ ìƒ‰ì¸ëœ ê²€ìƒ‰ì–´: {executed_queries}"

    new_task = Task(
        agent="vector_search_agent",
        done=False,
        description=task_desc,
        done_at=""
    )
    tasks.append(new_task)

    # ì‘ì—… í›„ê¸° ë©”ì‹œì§€
    msg_str = f"[WEB SEARCH AGENT] ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ì™„ë£Œ: {executed_queries}"
    messages.append(AIMessage(msg_str))
    print(msg_str)

    return {
        "messages": messages,
        "task_history": tasks,
        "references": state.get("references", {"queries": [], "docs": []}),  # referencesëŠ” vector_searchì—ì„œ ê°±ì‹ 
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì½˜í…ì¸  ì „ëµê°€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def content_strategist(state: State):
    print("\n\n============ CONTENT STRATEGIST ============")

    content_strategist_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ì±…ì„ ì“°ëŠ” AIíŒ€ì˜ ì½˜í…ì¸  ì „ëµê°€(Content Strategist)ë‹¤.
        ì´ì „ ëŒ€í™”ì™€ ê¸°ì¡´ ëª©ì°¨, ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬,
        ì±…ì˜ ì„¸ë¶€ ëª©ì°¨ë¥¼ ì‘ì„±í•˜ê±°ë‚˜(ì—†ìœ¼ë©´ ìƒì„±) ê¸°ì¡´ ëª©ì°¨ë¥¼ ê°œì„ í•œë‹¤.

        ì¶œë ¥ì€ 'ìµœì¢… ëª©ì°¨ í…ìŠ¤íŠ¸'ë§Œ ì‚°ì¶œí•˜ë¼. ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì œì™¸í•œë‹¤.

        --------------------------------
        - ì§€ë‚œ ëª©ì°¨:
        {outline}
        --------------------------------
        - ì´ì „ ëŒ€í™” ë‚´ìš©:
        {messages}
        --------------------------------
        - ì°¸ê³  ìë£Œ(ê²€ìƒ‰ ì§ˆì˜/ë¬¸ì„œ ìš”ì•½ ê°€ëŠ¥):
        {references}
        """
    )

    chain = content_strategist_system_prompt | llm | StrOutputParser()

    messages = state["messages"]
    outline = get_outline(current_path)

    inputs = {
        "messages": messages,
        "outline": outline,
        "references": state.get("references", {"queries": [], "docs": []}),
    }

    gathered = ""
    for chunk in chain.stream(inputs):
        gathered += chunk
        print(chunk, end="")
    print()

    save_outline(current_path, gathered)

    # ë©”ì‹œì§€ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    content_strategist_message = "[Content Strategist] ëª©ì°¨ ì‘ì„± ì™„ë£Œ"
    messages.append(AIMessage(content=content_strategist_message))
    task_history = state.get("task_history", [])
    if task_history[-1].agent != "content_strategist":
        raise ValueError(f"Content Strategistê°€ ì•„ë‹Œ agentê°€ ëª©ì°¨ ì‘ì„±ì„ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task_history[-1]}")
    task_history[-1].done = True
    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    new_task = Task(
        agent="communicator",
        done=False,
        description="AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ê³ , ì‚¬ìš©ìì˜ ì˜ê²¬ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤",
        done_at=""
    )
    task_history.append(new_task)

    print(new_task)

    return {
        "messages": messages,
        "task_history": task_history,
        "references": state.get("references", {"queries": [], "docs": []}),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì»¤ë®¤ë‹ˆì¼€ì´í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def communicator(state: State):
    print("\n\n============ COMMUNICATOR ============")

    communicator_system_prompt = PromptTemplate.from_template(
        """
        ë„ˆëŠ” ì±…ì„ ì“°ëŠ” AIíŒ€ì˜ ì»¤ë®¤ë‹ˆì¼€ì´í„°ë‹¤.
        AIíŒ€ì˜ ì§„í–‰ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ê°„ê²°íˆ ë³´ê³ í•˜ê³ , ë‹¤ìŒ ì§€ì‹œë¥¼ ë°›ëŠ”ë‹¤.
        ì‚¬ìš©ìëŠ” ì´ë¯¸ outline(ëª©ì°¨)ì„ ë³´ê³  ìˆë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ ëª©ì°¨ ì›ë¬¸ì„ ë‹¤ì‹œ ì¶œë ¥í•  í•„ìš”ëŠ” ì—†ë‹¤.

        ì°¸ê³ (í‘œì‹œ ê¸ˆì§€):
        outline: {outline}
        --------------------------------
        messages: {messages}
        """
    )

    system_chain = communicator_system_prompt | llm

    messages = state["messages"]
    inputs = {
        "messages": messages,
        "outline": get_outline(current_path),
    }

    print("\nAI\t: ", end="")
    gathered: BaseMessage | None = None
    for chunk in system_chain.stream(inputs):
        print(chunk.content, end="")
        if gathered is None:
            gathered = chunk
        else:
            gathered += chunk
    print()

    if gathered is None:
        gathered = AIMessage("ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    messages.append(gathered)

    task_history = state.get("task_history", [])
    if task_history[-1].agent != "communicator":
        raise ValueError(f"Communicatorê°€ ì•„ë‹Œ agentê°€ ëŒ€í™”ë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n {task_history[-1]}")
    task_history[-1].done = True
    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    return {
        "messages": messages,
        "task_history": task_history,
        "references": state.get("references", {"queries": [], "docs": []}),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangGraph ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

graph_builder = StateGraph(State)

graph_builder.add_node("supervisor", supervisor)
graph_builder.add_node("communicator", communicator)
graph_builder.add_node("content_strategist", content_strategist)
graph_builder.add_node("vector_search_agent", vector_search_agent)
graph_builder.add_node("web_search_agent", web_search_agent)

graph_builder.add_edge(START, "supervisor")
graph_builder.add_conditional_edges(
    "supervisor",
    supervisor_router,
    {
        "content_strategist": "content_strategist",
        "communicator": "communicator",
        "vector_search_agent": "vector_search_agent",
        "web_search_agent": "web_search_agent",
    },
)
graph_builder.add_edge("content_strategist", "communicator")
graph_builder.add_edge("web_search_agent", "vector_search_agent")
graph_builder.add_edge("vector_search_agent", "communicator")
graph_builder.add_edge("communicator", END)

graph = graph_builder.compile()

# Mermaid PNG ì €ì¥(ì˜µì…˜)
try:
    graph.get_graph().draw_mermaid_png(output_file_path=absolute_path.replace('.py', '.png'))
except Exception:
    pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def init_state() -> State:
    return State(
        messages=[
            SystemMessage(
                f"""
            ë„ˆí¬ AIë“¤ì€ ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ì±…ì„ ì“°ëŠ” ì‘ê°€íŒ€ì´ë‹¤.
            ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ëŒ€í™”í•˜ë¼.

            í˜„ì¬ì‹œê°ì€ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ì´ë‹¤.
            """
            )
        ],
        task_history=[],
        references={"queries": [], "docs": []},
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI ë£¨í”„(ì˜µì…˜) - ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_cli():
    state = init_state()
    while True:
        user_input = input("\nUser\t: ").strip()
        if user_input.lower() in ["exit", "quit", "q"]:
            print("Goodbye!")
            break

        state["messages"].append(HumanMessage(user_input))
        state = graph.invoke(state)

        print("\n------------------------------------ MESSAGE COUNT\t", len(state["messages"]))
        save_state(current_path, state)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gradio GUI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
ê°„ë‹¨í•œ 1-í˜ì´ì§€ UI:
- ì¢Œì¸¡: ì±„íŒ…(íˆìŠ¤í† ë¦¬)
- ìš°ì¸¡: í˜„ì¬ ì €ì¥ëœ outline / ìµœê·¼ ê²€ìƒ‰ ì§ˆì˜ / ì°¸ì¡° ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
- í•˜ë‹¨: ì‚¬ìš©ì ì…ë ¥ + ì „ì†¡/ì´ˆê¸°í™”
"""

def render_chat(messages: List[BaseMessage | str]) -> str:
    lines = []
    for msg in messages:
        role = "SYS"
        content = ""
        if isinstance(msg, SystemMessage):
            role = "SYSTEM"
            content = msg.content
        elif isinstance(msg, HumanMessage):
            role = "USER"
            content = msg.content
        elif isinstance(msg, AIMessage):
            role = "AI"
            content = msg.content
        elif isinstance(msg, str):
            role = "TEXT"
            content = msg
        else:
            role = msg.__class__.__name__.upper()
            content = getattr(msg, "content", str(msg))
        lines.append(f"**{role}:** {content}")
    return "\n\n".join(lines)


def render_references(refs: Dict[str, Any]) -> str:
    if not refs:
        return "(ì°¸ì¡° ì—†ìŒ)"
    queries = refs.get("queries", [])
    docs = refs.get("docs", [])
    lines = []
    if queries:
        lines.append("### ğŸ” ìµœê·¼ ê²€ìƒ‰ ì§ˆì˜")
        for i, q in enumerate(queries[-10:], 1):
            lines.append(f"{i}. {q}")
    if docs:
        lines.append("\n### ğŸ“„ ì°¸ì¡° ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 8ê°œ)")
        for i, d in enumerate(docs[:8], 1):
            preview = getattr(d, "page_content", "")
            meta = getattr(d, "metadata", {})
            src = meta.get("source") or meta.get("url") or ""
            # âœ…âœ…âœ… ì´ ë¶€ë¶„ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤ âœ…âœ…âœ…
            clean_preview = preview[:160].replace('\n', ' ')
            line = f"**{i}.** {clean_preview}" + (f"\nâ€” _{src}_" if src else "")
            lines.append(line)
    return "\n\n".join(lines) or "(ì°¸ì¡° ì—†ìŒ)"


def ui_on_send(user_text: str, state: State):
    try:
        if state is None:
            state = init_state()

        if user_text.strip():
            state["messages"].append(HumanMessage(user_text.strip()))
            new_state = graph.invoke(state)

            # ìƒíƒœ ì €ì¥
            save_state(current_path, new_state)

            chat_md = render_chat(new_state["messages"])
            outline_text = get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)"
            refs_md = render_references(new_state.get("references"))
            return chat_md, outline_text, refs_md, new_state
        else:
            chat_md = render_chat(state["messages"])
            outline_text = get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)"
            refs_md = render_references(state.get("references"))
            return chat_md, outline_text, refs_md, state
    except Exception as e:
        tb = traceback.format_exc()
        err_msg = f"[ì—ëŸ¬] {e}\n\n{tb}"
        chat_md = render_chat(state["messages"] if state else [])
        return chat_md + "\n\n" + err_msg, get_outline(current_path), "(ì°¸ì¡° ì—†ìŒ)", state


def ui_on_reset():
    state = init_state()
    return render_chat(state["messages"]), get_outline(current_path) or "(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)", "(ì°¸ì¡° ì—†ìŒ)", state


def launch_gradio():
    with gr.Blocks(title="AI Book Team (Ollama + DeepSeek-R1)") as demo:
        gr.Markdown("## âœï¸ AI Book Team (Local Ollama Â· DeepSeek-R1)\nì˜¤ë¥¸ìª½ì— ìµœì‹  ëª©ì°¨ì™€ ê²€ìƒ‰ ë ˆí¼ëŸ°ìŠ¤ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        with gr.Row():
            with gr.Column(scale=2):
                chat_md = gr.Markdown(value="")
                user_in = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì˜ˆ) 'AIë¡œ ì±…ì„ ì“°ê³  ì‹¶ì–´ìš”. ì£¼ì œëŠ” ...'")
                with gr.Row():
                    send_btn = gr.Button("ë³´ë‚´ê¸°", variant="primary")
                    reset_btn = gr.Button("ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
            with gr.Column(scale=1):
                outline_md = gr.Markdown(label="í˜„ì¬ ëª©ì°¨", value="(ì•„ì§ ëª©ì°¨ê°€ ì—†ìŠµë‹ˆë‹¤.)")
                refs_md = gr.Markdown(label="ê²€ìƒ‰ ë ˆí¼ëŸ°ìŠ¤", value="(ì°¸ì¡° ì—†ìŒ)")

        state_box = gr.State(init_state())

        send_btn.click(
            fn=ui_on_send,
            inputs=[user_in, state_box],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )
        user_in.submit(
            fn=ui_on_send,
            inputs=[user_in, state_box],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )
        reset_btn.click(
            fn=ui_on_reset,
            inputs=[],
            outputs=[chat_md, outline_md, refs_md, state_box],
        )

    demo.launch()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    # ê¸°ë³¸: Gradio GUI ì‹¤í–‰ (CLIê°€ í•„ìš”í•˜ë©´ run_cli() í˜¸ì¶œë¡œ êµì²´)
    launch_gradio()
    # run_cli()