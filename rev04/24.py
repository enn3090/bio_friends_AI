# -*- coding: utf-8 -*-
"""
DeepSeek-R1 (Ollama) + Gradio
Veo 3ìš© ê³ ë„í™” JSON í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°

- ë¡œì»¬ PCì— Ollamaì™€ deepseek-r1 ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
  ì„¤ì¹˜ ì˜ˆ:
    1) https://ollama.com ë‹¤ìš´ë¡œë“œ/ì„¤ì¹˜
    2) í„°ë¯¸ë„ì—ì„œ: ollama pull deepseek-r1
    3) ollama serve (ì¼ë°˜ì ìœ¼ë¡œ ìë™ ì‹¤í–‰ë¨, ê¸°ë³¸ í¬íŠ¸ 11434)

- ì´ ì•±ì€ ì‚¬ìš©ìì˜ 'ëŸ¬í”„ ë™ì˜ìƒ ì•„ì´ë””ì–´' ë¬¸ì¥ì„ ì…ë ¥ë°›ì•„
  Veo 3 ìŠ¤íƒ€ì¼ì˜ 'êµ¬ì¡°í™”ëœ JSON í”„ë¡¬í”„íŠ¸'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- ì¶œë ¥ì€ í•­ìƒ 'ìœ íš¨í•œ ë‹¨ì¼ JSON ê°ì²´'ê°€ ë˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.

í•„ìš” íŒ¨í‚¤ì§€:
    pip install gradio requests
"""

import os
import re
import json
import time
import tempfile
from typing import Tuple, Any, Dict

import requests
import gradio as gr


# =========================
# Ollama(ë¡œì»¬ LLM) í˜¸ì¶œ ìœ í‹¸
# =========================

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
MODEL_NAME = os.getenv("OLLAMA_MODEL", "deepseek-r1")  # ë¡œì»¬ì— ì„¤ì¹˜ëœ ëª¨ë¸ ì´ë¦„


def _ollama_generate(prompt: str, temperature: float = 0.6, max_tokens: int = 2048, stop=None) -> str:
    """
    Ollama /api/generate í˜¸ì¶œ (ë¹„ìŠ¤íŠ¸ë¦¬ë°). deepseek-r1 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - prompt: ë‹¨ì¼ ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ (system + user ì§€ì‹œ í¬í•¨)
    - temperature, max_tokens: ìƒì„± ì˜µì…˜
    - stop: ì¤‘ë‹¨ í† í° ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["```"])
    """
    url = f"{OLLAMA_URL}/api/generate"
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": float(temperature),
            "num_ctx": 8192,
            "top_p": 0.95,
            "repeat_penalty": 1.1,
            "stop": stop or ["```", "</think>", "</thinking>", "<|eot_id|>"],
            # deepseek-r1ì´ ì‚¬ê³ íë¦„ì„ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ ìœ ë„
        },
    }
    try:
        resp = requests.post(url, json=payload, timeout=120)
        resp.raise_for_status()
        data = resp.json()
        return data.get("response", "")
    except requests.RequestException as e:
        raise RuntimeError(f"[Ollama ì—°ê²° ì˜¤ë¥˜] {e}\n"
                           f"- Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” (ê¸°ë³¸: {OLLAMA_URL}).\n"
                           f"- deepseek-r1 ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”: `ollama pull deepseek-r1`") from e


# =========================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ì—­í•  ì§€ì‹œ)
# =========================

def build_system_instructions(structure_mode: str, force_no_text: bool) -> str:
    """
    ì‚¬ìš©ì ëŸ¬í”„ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, Veo 3ìš© ê³ í’ˆì§ˆ JSON í”„ë¡¬í”„íŠ¸ë§Œ ì‚°ì¶œí•˜ë„ë¡ í•˜ëŠ”
    ì‹œìŠ¤í…œ ë ˆë²¨ ì§€ì‹œë¬¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    advanced_hint = ""
    if structure_mode == "Standard (Single Shot)":
        advanced_hint = (
            "Use ONLY the Standard JSON Structure.\n"
            "Output must be a single JSON object with the keys: "
            '["description","style","camera","lighting","environment","elements","motion","ending","text","keywords"].\n'
        )
    elif structure_mode == "Sequential (Multi-Part)":
        advanced_hint = (
            "Use ONLY the Sequential Shot Structure.\n"
            "Output must be a single JSON object with keys at minimum: "
            '["scene","style","sequence","audio"].\n'
            "The 'sequence' must be an array of objects describing continuous shots and transitions without hard cuts.\n"
        )
    elif structure_mode == "Timeline (Timestamped)":
        advanced_hint = (
            "Use ONLY the Timeline-Based Structure.\n"
            "Output must be a single JSON object with keys at minimum: "
            '["metadata","camera_setup","key_elements","timeline"].\n'
            'Include "aspect_ratio" inside "metadata".\n'
        )
    else:
        # Auto: ëª¨ë¸ì´ ì•„ì´ë””ì–´ ë³µì¡ë„ì— ë”°ë¼ ìµœì  êµ¬ì¡°ë¥¼ ì„ íƒ
        advanced_hint = (
            "Choose the best-fitting structure (Standard / Sequential / Timeline) based on user intent.\n"
            "Always output a SINGLE JSON object representing the chosen structure.\n"
        )

    text_rule = 'The "text" field MUST be "none".\n' if force_no_text else \
        'If no overlay is needed, set "text" to "none".\n'

    # ì›ë¬¸ ì§€ì‹œë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨í•˜ì—¬ LLMì´ ìŠì§€ ì•Šë„ë¡ ê³ ì •
    core_instruction = r"""
Agent Instructions: Generating High-Quality Prompts for Veo 3
Your primary goal is to generate a structured and highly descriptive prompt in JSON format. This allows the AI to parse distinct creative and technical elements for precise video generation. The most successful prompts follow a pattern of "object-centric magical transformation," where a single product or object triggers a dynamic and cinematic unfolding of a larger scene.

There are two primary structures to use: the Standard JSON Structure for single, continuous shots, and the Advanced Sequential/Timeline Structure for more complex, multi-part scenes.

1. The Standard JSON Structure
This is the default and most common format. Use it for concepts that can be captured in a single, continuous camera motion, even if the action within the frame is complex.

Your output must be a single JSON object with the following keys. Be descriptive and evocative in your values.

"description": (String) A comprehensive, one-paragraph summary of the entire video concept from start to finish. This is the high-level narrative.
"style": (String) Overall visual aesthetic and mood.
"camera": (String) Angle, movement, and lens style (filmmaking terminology).
"lighting": (String) Lighting style, time of day, and color palette.
"environment": (String) Setting/location; static or transforming.
"elements": (Array of Strings) Key nouns/visual components.
"motion": (String) Sequence of actions/transformations (A > B > C).
"ending": (String) Final shot/lasting image.
"text": (String) Overlay text; if none, explicitly "none".
"keywords": (Array of Strings) Tags including aspect ratio ("16:9"), core subject, actions, style, technical attributes.

2. Advanced Structures (Use When Necessary)
A) Sequential Shot Structure (multi-part, continuous motion without hard cuts):
{
  "scene": "animation",
  "style": "Futuristic Apple-style minimalism, photorealistic...",
  "sequence": [
    {"shot": "Logo Reveal", "camera": "slow push-in", "description": "Begin with the brand logo floating..."},
    {"transition": "Without any cut, the camera smoothly moves closer..."},
    {"shot": "Product Formation", "camera": "continuous motion, no cut", "description": "The particles condense and materialize..."}
  ],
  "audio": {"soundtrack": "Soft, futuristic ambient music..."}
}

B) Timeline-Based Structure (precise timing; timestamps and beats):
{
  "metadata": {"prompt_name": "NYC City Assembly", "base_style": "cinematic, photorealistic, 4K", "aspect_ratio": "16:9"},
  "camera_setup": "A single, fixed, wide-angle shot...",
  "key_elements": {...},
  "timeline": [
    {"sequence": 1, "timestamp": "00:00-00:01", "action": "In the center of the barren plaza...", "audio": "Deep, resonant rumble..."},
    {"sequence": 2, "timestamp": "00:01-00:02", "action": "The container's steel doors burst open...", "audio": "Sharp metallic clang..."}
  ]
}

Guiding Principles:
- ALWAYS OUTPUT VALID JSON: a single well-formed JSON object. No explanations or comments.
- Embrace "magical realism / assembly" centered on an object catalyst.
- Think like a director: dolly, crane, orbit, low angle, golden hour, lens flare.
- Be hyper-specific and sensory. Mention condensation, glistening surfaces, steam, sparks, textures.
- Deconstruct the motion: describe the chain precisely (A > B > C).
- Use "keywords" to reinforce concepts including "16:9" or another aspect ratio plus style/tech specs (e.g., 4K).
"""

    # ìµœì¢… ì‹œìŠ¤í…œ ì§€ì‹œ ì¡°í•©
    system = (
        "You are a prompt-engineering director for Veo 3 video generation.\n"
        "Your job: Return ONLY a single valid JSON object tailored to the user's idea.\n"
        "Do NOT include any prose before or after the JSON. No markdown fences.\n"
        f"{advanced_hint}"
        f"{text_rule}"
        + core_instruction
    )
    return system


# =========================
# JSON ì •ì œ/ê²€ì¦ ìœ í‹¸
# =========================

def extract_first_json_blob(text: str) -> str:
    """
    LLMì´ í˜¹ì‹œë¼ë„ ì£¼ë³€ í…ìŠ¤íŠ¸ë¥¼ ì„ì–´ ë³´ëƒˆì„ ê²½ìš°, ì²« ë²ˆì§¸ JSON ê°ì²´ ë¸”ë¡ë§Œ ì¶”ì¶œ.
    ì¤‘ê´„í˜¸ ê´„í˜¸ìˆ˜ ì¹´ìš´íŒ…ìœ¼ë¡œ ê°€ì¥ ê·¸ëŸ´ë“¯í•œ JSONì„ ë³µêµ¬ ì‹œë„.
    """
    # ë¹ ë¥¸ ê²½ë¡œ: ì´ë¯¸ ì˜¬ë°”ë¥¸ JSONì¼ ìˆ˜ ìˆìŒ
    try:
        json.loads(text)
        return text
    except Exception:
        pass

    # ì½”ë“œë¸”ë¡ ì œê±°
    text = re.sub(r"```(?:json)?\s*|\s*```", "", text).strip()

    # ì¤‘ê´„í˜¸ ê· í˜•ìœ¼ë¡œ ì²« ê°ì²´ ì°¾ê¸°
    start_indices = [m.start() for m in re.finditer(r"\{", text)]
    for start in start_indices:
        depth = 0
        for i in range(start, len(text)):
            if text[i] == "{":
                depth += 1
            elif text[i] == "}":
                depth -= 1
                if depth == 0:
                    candidate = text[start:i + 1]
                    try:
                        json.loads(candidate)
                        return candidate
                    except Exception:
                        continue
    # ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜ (í›„ì† ë‹¨ê³„ì—ì„œ ì˜ˆì™¸ í‘œì‹œ)
    return text


def ensure_json_object(structure_mode: str, data: Any) -> Dict[str, Any]:
    """
    êµ¬ì¡° ëª¨ë“œì— ë§ëŠ” ìµœì†Œ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ê°’ì„ ì±„ì›Œ ë„£ìŠµë‹ˆë‹¤.
    - ëª¨ë¸ ì¶œë ¥ì´ ì‚´ì§ ëˆ„ë½í•´ë„ UIê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ê°€ë²¼ìš´ ë³´ì •ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    if not isinstance(data, dict):
        raise ValueError("LLM ì¶œë ¥ì´ JSON ê°ì²´ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    if structure_mode == "Standard (Single Shot)" or (
        structure_mode == "Auto (Let Model Decide)" and all(k not in data for k in ["scene", "metadata"])
    ):
        # í‘œì¤€ êµ¬ì¡° ìµœì†Œ í‚¤
        defaults = {
            "description": "",
            "style": "",
            "camera": "",
            "lighting": "",
            "environment": "",
            "elements": [],
            "motion": "",
            "ending": "",
            "text": "none",
            "keywords": ["16:9", "cinematic", "4K"]
        }
        for k, v in defaults.items():
            data.setdefault(k, v)

    elif structure_mode == "Sequential (Multi-Part)" or ("sequence" in data and isinstance(data.get("sequence"), list)):
        data.setdefault("scene", "animation")
        data.setdefault("style", "")
        data.setdefault("sequence", [])
        data.setdefault("audio", {"soundtrack": ""})

    elif structure_mode == "Timeline (Timestamped)" or ("timeline" in data and isinstance(data.get("timeline"), list)):
        meta = data.setdefault("metadata", {})
        meta.setdefault("prompt_name", "Untitled Prompt")
        meta.setdefault("base_style", "cinematic, photorealistic, 4K")
        meta.setdefault("aspect_ratio", "16:9")
        data.setdefault("camera_setup", "")
        data.setdefault("key_elements", {})
        data.setdefault("timeline", [])

    return data


# =========================
# í”„ë¡¬í”„íŠ¸ ê²°í•©
# =========================

def compose_prompt(system_msg: str, user_idea: str) -> str:
    """
    Ollamaì˜ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ì— system/user ì—­í• ì„ í•¨ê»˜ ë„£ëŠ” í¬ë§·.
    deepseek-r1ì´ ì‚¬ê³ íë¦„ì„ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ 'ìµœì¢… JSONë§Œ' ê°•ì¡°.
    """
    return (
        "<system>\n" + system_msg.strip() + "\n</system>\n"
        "<user>\n"
        "Below is the user's rough video concept. Transform it into a SINGLE valid JSON object, "
        "following the above rules and structures. Be richly descriptive, cinematic, and sensory. "
        "Do NOT include explanations. JSON only.\n\n"
        f"User Idea:\n{user_idea.strip()}\n"
        "</user>\n"
        "<assistant>\n"
    )


# =========================
# Gradio ì•¡ì…˜ í•¨ìˆ˜
# =========================

def generate_json_prompt(user_idea: str,
                         structure_mode: str = "Auto (Let Model Decide)",
                         force_no_text: bool = True,
                         temperature: float = 0.6,
                         max_tokens: int = 2048) -> Tuple[Dict[str, Any], str]:
    """
    Gradioì—ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ í•¨ìˆ˜.
    - user_idea: ì‚¬ìš©ìì˜ ëŸ¬í”„ ì•„ì´ë””ì–´(í•œ ë¬¸ì¥ ì´ìƒ)
    - structure_mode: í‘œì¤€/ì‹œí€€ì…œ/íƒ€ì„ë¼ì¸/ìë™
    - force_no_text: í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ë¥¼ ê°•ì œë¡œ "none"ìœ¼ë¡œ
    - temperature, max_tokens: LLM ìƒì„± ì˜µì…˜
    ë°˜í™˜:
      (JSON ê°ì²´(dict), ë””ë²„ê·¸ ì›ë¬¸ í…ìŠ¤íŠ¸)
    """
    if not user_idea or not user_idea.strip():
        raise gr.Error("ëŸ¬í”„ ë™ì˜ìƒ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    system_msg = build_system_instructions(structure_mode, force_no_text)
    prompt = compose_prompt(system_msg, user_idea)

    # LLM í˜¸ì¶œ
    raw = _ollama_generate(prompt, temperature=temperature, max_tokens=max_tokens)

    # JSONë§Œ ì¶”ì¶œ/ê²€ì¦
    blob = extract_first_json_blob(raw)
    try:
        data = json.loads(blob)
    except Exception as e:
        # í•œ ë²ˆ ë” ì—„ê²© ì§€ì‹œë¡œ ì¬ì‹œë„ (ìë™ ë³µêµ¬)
        stricter = system_msg + "\nSTRICT RULE: Output ONLY a single valid JSON object. No extra text."
        prompt2 = compose_prompt(stricter, user_idea)
        raw2 = _ollama_generate(prompt2, temperature=temperature, max_tokens=max_tokens)
        blob2 = extract_first_json_blob(raw2)
        try:
            data = json.loads(blob2)
            raw = raw2
            blob = blob2
        except Exception:
            raise gr.Error(f"ëª¨ë¸ ì¶œë ¥ì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.\n--- ì›ë¬¸ ---\n{raw[:1500]}") from e

    # êµ¬ì¡°ì— ë§ëŠ” ìµœì†Œ í‚¤ ë³´ì •
    data = ensure_json_object(structure_mode, data)

    # í…ìŠ¤íŠ¸ ê°•ì œ ì˜µì…˜ ì ìš©
    if force_no_text and isinstance(data, dict):
        if "text" in data and isinstance(data["text"], str):
            data["text"] = "none"

    # ê¹”ë”í•˜ê²Œ ì •ë ¬ëœ JSONê³¼ ë””ë²„ê·¸ ì›ë¬¸ì„ ë°˜í™˜
    return data, blob


def save_json_to_file(data: Dict[str, Any]) -> str:
    """
    ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ìš© JSON íŒŒì¼ ìƒì„±.
    """
    pretty = json.dumps(data, ensure_ascii=False, indent=2)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".json")
    with open(tmp.name, "w", encoding="utf-8") as f:
        f.write(pretty)
    return tmp.name


# =========================
# Gradio UI
# =========================

with gr.Blocks(theme=gr.themes.Soft(), title="Veo 3 JSON Prompt Generator (DeepSeek-R1 Â· Ollama)") as demo:
    gr.Markdown(
        """
# Veo 3 JSON í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
**DeepSeek-R1 (Ollama, ë¡œì»¬) + Gradio**

- ì‚¬ìš©ë²•: ëŸ¬í”„í•œ ë™ì˜ìƒ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ë©´, Veo 3ìš© ê³ ë„í™”ëœ **ë‹¨ì¼ JSON ê°ì²´**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
- êµ¬ì¡° ì„ íƒ:
  - **Standard**: í•œ ë²ˆì˜ ì—°ì† ì‡¼íŠ¸(ì¹´ë©”ë¼ ëª¨ì…˜ì€ ë³µì¡í•´ë„ ì»· ì—†ì´)ì¸ ê²½ìš°
  - **Sequential**: ì»· ì—†ì´ ì´ì–´ì§€ëŠ” ë‹¤ì¤‘ ë‹¨ê³„/ì‡¼íŠ¸
  - **Timeline**: íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ì •ë°€ ì œì–´ (ì‚¬ìš´ë“œ í ë™ê¸°í™” ë“±)
  - **Auto**: ëª¨ë¸ì´ ì•„ì´ë””ì–´ì— ë§ì¶° ìµœì  êµ¬ì¡°ë¥¼ ì„ íƒ
        """
    )

    with gr.Row():
        structure_mode = gr.Dropdown(
            choices=[
                "Auto (Let Model Decide)",
                "Standard (Single Shot)",
                "Sequential (Multi-Part)",
                "Timeline (Timestamped)",
            ],
            value="Auto (Let Model Decide)",
            label="êµ¬ì¡° ì„ íƒ"
        )
        force_no_text = gr.Checkbox(value=True, label='í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ë¥¼ í•­ìƒ "none"ìœ¼ë¡œ', info="ë¸Œëœë“œ í…ìŠ¤íŠ¸ ê¸ˆì§€ ì‹œ ìœ ìš©")

    user_idea = gr.Textbox(
        label="ëŸ¬í”„ ë™ì˜ìƒ ì•„ì´ë””ì–´ ì…ë ¥",
        placeholder="ì˜ˆ) ì°¨ê°€ìš´ ì½œë¼ ìº”ì´ í…Œì´ë¸” ì¤‘ì•™ì—ì„œ ì„œì„œíˆ ì„±ì—ê°€ ë§ºíˆê³ , íƒ­ì´ ì²œì²œíˆ ì—´ë¦¬ë©° ì£¼ë³€ì´ ë„¤ì˜¨ ë„ì‹œë¡œ ë³€ëª¨í•˜ëŠ” ë§ˆë²•ì  ë³€í™˜...",
        lines=6
    )

    with gr.Accordion("ê³ ê¸‰ ì˜µì…˜", open=False):
        temperature = gr.Slider(0.0, 1.2, value=0.6, step=0.05, label="ì°½ì˜ì„± (temperature)")
        max_tokens = gr.Slider(256, 4096, value=2048, step=64, label="ìµœëŒ€ í† í°(íŒíŠ¸)")

    with gr.Row():
        gen_btn = gr.Button("ğŸš€ í”„ë¡¬í”„íŠ¸ ìƒì„±", variant="primary")
        sample_btn = gr.Button("âœ¨ ì˜ˆì‹œ ì•„ì´ë””ì–´ ì±„ìš°ê¸°")

    with gr.Row():
        json_view = gr.JSON(label="ìƒì„±ëœ JSON (ê²€ì¦/ë³´ì • ì™„ë£Œ)")
        raw_view = gr.Code(label="LLM ì›ë¬¸(JSONë§Œ ì¶”ì¶œ)", language="json")

    download_btn = gr.DownloadButton(label="â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ", file_name="veo3_prompt.json")

    # ì´ë²¤íŠ¸ ë°”ì¸ë”©
    def on_generate(user_idea, structure_mode, force_no_text, temperature, max_tokens):
        data, raw = generate_json_prompt(
            user_idea=user_idea,
            structure_mode=structure_mode,
            force_no_text=force_no_text,
            temperature=temperature,
            max_tokens=int(max_tokens),
        )
        return data, raw, gr.update(value=save_json_to_file(data))

    gen_btn.click(
        on_generate,
        inputs=[user_idea, structure_mode, force_no_text, temperature, max_tokens],
        outputs=[json_view, raw_view, download_btn]
    )

    def fill_sample():
        return (
            "íƒì ì¤‘ì•™ì˜ ìœ ë¦¬ ë³‘(ë¬´í‘œê¸°)ì´ ì°¨ê°‘ê²Œ ë¹›ë‚˜ë©° ë¯¸ì„¸í•œ ë¬¼ë°©ìš¸ì´ ë§ºíŒë‹¤. ë³‘ì˜ ë§ˆê°œê°€ "
            "ë”± ì†Œë¦¬ë¥¼ ë‚´ë©° ì²œì²œíˆ ë– ì˜¤ë¥´ê³ , ë³‘ ì…êµ¬ì—ì„œ ë¯¸ì„¸í•œ ê¸ˆë¹› ì…ìë“¤ì´ ë¶„ì¶œë˜ì–´ ê³µì¤‘ì—ì„œ "
            "ë¦¬ë³¸ì²˜ëŸ¼ ì†Œìš©ëŒì´ì¹œë‹¤. ìˆœê°„ ë°© ì „ì²´ê°€ í™©ê¸ˆë¹› ì„ì–‘ í†¤ìœ¼ë¡œ ë¬¼ë“¤ë©° ë²½ì´ ì‚¬ë¼ì§€ê³ , "
            "ë„“ì€ ëª¨ë˜ ì‚¬ë§‰ê³¼ í˜„ëŒ€ì  ë„ì‹œì˜ ìŠ¤ì¹´ì´ë¼ì¸ì´ ì´ì–´ì§„ ì´ˆí˜„ì‹¤ ê³µê°„ìœ¼ë¡œ ì—°ì† ë³€í™˜ëœë‹¤. "
            "ì¹´ë©”ë¼ëŠ” ë‚®ì€ ë¡œìš° ì•µê¸€ì˜ ëŠë¦° ì˜¤ë¹„íŠ¸ë¡œ ì‹œì‘í•´ ìƒê³µ íƒ‘ë‹¤ìš´ìœ¼ë¡œ ì—°ê²°ë˜ë©°, ì…ìë“¤ì´ "
            "ìœ ë¦¬ë³‘ ë¼ë²¨ í˜•íƒœë¥¼ ìŠ¤ìŠ¤ë¡œ ì¡°ë¦½í–ˆë‹¤ê°€ ë„ì‹œ ì „ì²´ì˜ ë„¤ì˜¨ ì¶•ì œë¡œ ì¦í­ëœë‹¤. í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ëŠ” ë¶ˆí•„ìš”."
        )

    sample_btn.click(fill_sample, outputs=[user_idea])


if __name__ == "__main__":
    # ê³µìœ  ëª¨ë“œ í•„ìš” ì‹œ share=True
    demo.launch(server_name="0.0.0.0", server_port=7860, show_api=False)

