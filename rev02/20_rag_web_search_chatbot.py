"""
[OpenCode ë³€í™˜ë³¸]

ëª©í‘œ: OpenAI + Streamlit ê¸°ë°˜ ê²€ìƒ‰/RAG ìƒ˜í”Œ ì½”ë“œë¥¼
â†’ **ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ LLM (Ollama: DeepSeek-R1)** + **Gradio UI** + **DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰** + **ì›¹ìŠ¤í¬ë˜í•‘(WebBaseLoader/bs4)** ë¡œ ë³€í™˜

í•µì‹¬ í¬ì¸íŠ¸
1) ChatOpenAI â†’ ChatOllama (ë¡œì»¬ Ollama, API Key ë¶ˆí•„ìš”)
2) Streamlit â†’ Gradio ChatInterface (ê°„ë‹¨í•œ UI, ë¹„ë™ê¸° ì§€ì›)
3) DuckDuckGo ê²€ìƒ‰(`langchain_community.tools.DuckDuckGoSearchResults`)ë¡œ ë‰´ìŠ¤ ìœ„ì£¼ ê²€ìƒ‰
4) ê²€ìƒ‰ ê²°ê³¼ ë§í¬ë¥¼ íŒŒì‹±í•˜ì—¬ **WebBaseLoader.aload()**(ë¹„ë™ê¸°)ë¡œ ë³¸ë¬¸ ìˆ˜ì§‘ + bs4 ë°±ì—… íŒŒì„œ
5) ìˆ˜ì§‘ ë¬¸ì„œë“¤ì„ **context**ë¡œ ë„£ì–´ LLMì— ì§ˆì˜(ê°„ë‹¨í•œ Stuff-RAG)
6) DeepSeek-R1ì˜ ë‚´ë¶€ ì‚¬ê³ (<think>...</think>)ëŠ” ì‚¬ìš©ì ì¶œë ¥ì—ì„œ ì œê±°

ì‚¬ì „ ì¤€ë¹„
- Ollama ì„¤ì¹˜ & ëª¨ë¸ ì¤€ë¹„:
    - https://ollama.com
    - `ollama pull deepseek-r1:latest`
- íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
    pip install gradio langchain langchain-community duckduckgo-search chromadb beautifulsoup4 requests
"""

from __future__ import annotations

import asyncio
import re
from typing import List, Tuple

import gradio as gr

# LangChain ë©”ì‹œì§€/í”„ë¡¬í”„íŠ¸/íŒŒì„œ
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# ë¡œì»¬ Ollama ëª¨ë¸
from langchain_community.chat_models import ChatOllama

# DuckDuckGo ê²€ìƒ‰
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain_community.tools import DuckDuckGoSearchResults

# ì›¹ ë¬¸ì„œ ë¡œë”(ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘)
from langchain_community.document_loaders import WebBaseLoader

# ========= ì„¤ì • =========
MODEL_NAME = "deepseek-r1:latest"        # í•„ìš” ì‹œ "deepseek-r1:7b" / "deepseek-r1:14b"
TEMPERATURE = 0.7
SYSTEM_PROMPT = "ë„ˆëŠ” ë¬¸ì„œ(ë‰´ìŠ¤/ì›¹í˜ì´ì§€)ì— ê¸°ë°˜í•´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” ì‚°ì—…Â·ìë™ì°¨ ì •ì±…/ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì•¼."
DDG_REGION = "kr-kr"  # í•œêµ­ ê²°ê³¼ ìš°ì„ 
DDG_TIME = "w"        # ìµœê·¼ 1ì£¼ (d=1ì¼, m=1ë‹¬ ë“±)
DDG_SOURCE = "news"   # ë‰´ìŠ¤ì— í•œì •

# DeepSeek-R1 ë‚´ë¶€ ì‚¬ê³  ì œê±°
THINK_TAG_RE = re.compile(r"<think>.*?</think>", re.DOTALL)


def strip_think(text: str) -> str:
    return THINK_TAG_RE.sub("", text).strip()


# ========= LLM ì¤€ë¹„ =========
llm = ChatOllama(
    model=MODEL_NAME,
    temperature=TEMPERATURE,
    # base_url="http://localhost:11434",  # ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ ìƒëµ ê°€ëŠ¥
)


# ========= í”„ë¡¬í”„íŠ¸ & ì²´ì¸ =========
# ê°„ë‹¨ Stuff-RAG: context(ë‰´ìŠ¤/ì›¹ ë³¸ë¬¸) + ëŒ€í™” ë©”ì‹œì§€ë¥¼ í•©ì³ ë‹µë³€
question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "ì•„ë˜ëŠ” ìµœì‹  ë‰´ìŠ¤/ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ì»¨í…ìŠ¤íŠ¸ë‹¤. ë°˜ë“œì‹œ ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë¼. "
            "ë¶ˆí™•ì‹¤í•˜ë©´ ì¶”ì •ì„ ì¤„ì´ê³  'ë¶ˆí™•ì‹¤í•¨'ì„ ëª…ì‹œí•˜ë¼.\n\n{context}",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)
document_chain = question_answering_prompt | llm | StrOutputParser()


# ========= DuckDuckGo ê²€ìƒ‰ ìœ í‹¸ =========
def make_news_search_tool() -> DuckDuckGoSearchResults:
    wrapper = DuckDuckGoSearchAPIWrapper(region=DDG_REGION, time=DDG_TIME)
    return DuckDuckGoSearchResults(
        api_wrapper=wrapper,
        source=DDG_SOURCE,
        results_separator=";\n",
    )


def parse_links_from_search_output(docs_str: str) -> List[str]:
    """
    DuckDuckGoSearchResults.invoke ì˜ ë¬¸ìì—´ ê²°ê³¼ì—ì„œ 'link:' ì´í›„ ë¶€ë¶„ì„ ì¶”ì¶œ.
    ê° í•­ëª©ì€ '...;\\n' ë¡œ êµ¬ë¶„ë¨.
    """
    links: List[str] = []
    if not docs_str:
        return links
    for item in docs_str.split(";\n"):
        item = item.strip()
        if not item:
            continue
        if "link:" in item:
            # 'link:' ì´í›„ë¥¼ URLë¡œ ê°„ì£¼
            try:
                link = item.split("link:")[1].strip()
                if link:
                    links.append(link)
            except Exception:
                continue
    # ì¤‘ë³µ ì œê±°
    return list(dict.fromkeys(links))


# ========= ì›¹ ë³¸ë¬¸ ìˆ˜ì§‘ (ìš°ì„  WebBaseLoader, ì‹¤íŒ¨ ì‹œ bs4 ë°±ì—…) =========
async def load_pages_async(urls: List[str]) -> List[str]:
    """
    WebBaseLoader.aload()ë¡œ ë¹„ë™ê¸° ìˆ˜ì§‘. ì‹¤íŒ¨í•˜ë©´ requests+bs4 ë¡œ ë°±ì—… íŒŒì‹±.
    """
    texts: List[str] = []

    if not urls:
        return texts

    try:
        loader = WebBaseLoader(
            web_paths=urls,
            bs_get_text_kwargs={"strip": True},
        )
        # LangChain ë¹„ë™ê¸° ë¡œë”©
        docs = await loader.aload()
        for d in docs:
            content = (d.page_content or "").strip()
            if content:
                texts.append(content)
    except Exception:
        # ì¼ë¶€ URLì€ ë¡œë”ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ bs4 ë°±ì—… ìˆ˜í–‰
        texts.extend(await fallback_fetch_many(urls))

    # ë„ˆë¬´ ê¸´ ì»¨í…ìŠ¤íŠ¸ëŠ” ìš”ì•½/ì ˆë‹¨ (ê°„ë‹¨íˆ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©)
    MAX_CHARS = 12000
    joined = "\n\n---\n\n".join(texts)
    if len(joined) > MAX_CHARS:
        joined = joined[:MAX_CHARS] + "\n\n[ì»¨í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ ì¼ë¶€ë§Œ ì‚¬ìš©ë¨]"
    return [joined]


async def fallback_fetch_many(urls: List[str]) -> List[str]:
    """
    requests + bs4 ë¡œ ìˆœì°¨ ìˆ˜ì§‘ (ê°„ë‹¨ ë°±ì—…). ë¹„ë™ê¸° ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶”ê¸° ìœ„í•´ asyncio.to_thread ì‚¬ìš©.
    """
    import requests
    from bs4 import BeautifulSoup

    def fetch_one(url: str) -> str:
        try:
            r = requests.get(url, timeout=12)
            r.raise_for_status()
            soup = BeautifulSoup(r.content, "html.parser")
            # ìš°ì„  article íƒœê·¸ â†’ ì—†ìœ¼ë©´ ë³¸ë¬¸ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” í° div
            art = soup.find("article")
            if art:
                return art.get_text(" ", strip=True)
            # ì¼ë¶€ ì–¸ë¡ ì‚¬ ì»¤ìŠ¤í…€ ì»¨í…Œì´ë„ˆ ëŒ€ì‘
            cand_ids = ["CmAdContent", "news-contents", "dic_area", "articeBody"]
            for cid in cand_ids:
                node = soup.find("div", id=cid)
                if node:
                    return node.get_text(" ", strip=True)
            # ì „ì²´ í…ìŠ¤íŠ¸ (ê°„ë‹¨ í´ë°±)
            return soup.get_text(" ", strip=True)
        except Exception:
            return ""

    texts: List[str] = []
    for url in urls:
        txt = await asyncio.to_thread(fetch_one, url)
        if txt:
            texts.append(txt)
    return texts


# ========= Gradio <-> LangChain íˆìŠ¤í† ë¦¬ ë³€í™˜ =========
def history_to_messages(history: List[Tuple[str, str]]) -> List:
    msgs: List = [SystemMessage(SYSTEM_PROMPT)]
    for u, a in history:
        if u:
            msgs.append(HumanMessage(u))
        if a:
            msgs.append(AIMessage(a))
    return msgs


# ========= ë©”ì¸ ì‘ë‹µ(ë¹„ë™ê¸°) =========
async def respond(user_input: str, history: List[Tuple[str, str]]):
    """
    1) DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰ â†’ ë§í¬ ì¶”ì¶œ
    2) ë§í¬ ë³¸ë¬¸ ìˆ˜ì§‘(WebBaseLoader â†’ bs4 ë°±ì—…)
    3) ì»¨í…ìŠ¤íŠ¸ì™€ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ LLM í˜¸ì¶œ
    4) <think> ì œê±° í›„ ë°˜í™˜
    """
    # 1) ë‰´ìŠ¤ ê²€ìƒ‰
    search_tool = make_news_search_tool()
    search_query = user_input.strip()
    docs_str = search_tool.invoke(search_query)  # ë¬¸ìì—´ ë°˜í™˜
    links = parse_links_from_search_output(docs_str)

    # ìš°ì¸¡ íŒ¨ë„(ê²€ìƒ‰ ìš”ì•½) í‘œì‹œìš©
    side_info = [
        "### ğŸ” ê²€ìƒ‰ ìš”ì•½",
        f"- ì¿¼ë¦¬: `{search_query}`",
        f"- ë§í¬ ìˆ˜: **{len(links)}**",
    ]
    if links:
        side_info.append("- ìƒìœ„ ë§í¬:")
        side_info.extend([f"  - {u}" for u in links[:6]])
    side_md = "\n".join(side_info)

    # 2) ë³¸ë¬¸ ìˆ˜ì§‘
    page_texts_joined_list = await load_pages_async(links)
    context_text = page_texts_joined_list[0] if page_texts_joined_list else docs_str

    # 3) LLM í˜¸ì¶œ
    messages = history_to_messages(history) + [HumanMessage(user_input)]
    try:
        answer = await document_chain.ainvoke(
            {"messages": messages, "context": context_text}
        )
    except Exception as e:
        answer = f"ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    answer = strip_think(answer)

    # ìµœì¢… ì‘ë‹µ + ìš°ì¸¡ íŒ¨ë„ ìš”ì•½
    return answer, side_md


# ========= Gradio UI =========
with gr.Blocks(css="footer {visibility: hidden}") as demo:
    gr.Markdown("## ğŸš—ğŸ“ˆ í˜„ëŒ€ì°¨ ë“± ì‚°ì—… ì „ë§ Q&A (DeepSeek-R1 on Ollama + DuckDuckGo RAG)")

    chat = gr.ChatInterface(
        fn=respond,  # async í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥
        additional_outputs=[gr.Markdown(label="ê²€ìƒ‰/ì»¨í…ìŠ¤íŠ¸ ìš”ì•½")],
        chatbot=gr.Chatbot(
            label="ì‹œì¥ë¶„ì„ ì „ë¬¸ê°€",
            height=520,
        ),
        title="",
        description=(
            "ë¡œì»¬ **Ollama(DeepSeek-R1)** ëª¨ë¸ë¡œ ë™ì‘í•©ë‹ˆë‹¤. DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰ â†’ ë³¸ë¬¸ ìˆ˜ì§‘ â†’ RAGë¡œ ë‹µë³€í•´ìš”.\n"
            "â€» ëª¨ë¸ì˜ ë‚´ë¶€ ì‚¬ê³ (<think>...</think>)ëŠ” ìë™ ìˆ¨ê¹€"
        ),
        theme="soft",
        retry_btn="ë‹¤ì‹œ ìƒì„±",
        undo_btn="ì´ì „ ë©”ì‹œì§€ ì‚­ì œ",
        clear_btn="ëŒ€í™” ì´ˆê¸°í™”",
        examples=[
            "2025ë…„ í˜„ëŒ€ìë™ì°¨ ë¯¸êµ­ ì‹œì¥ ì „ë§ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì „ê¸°ì°¨ ì¸ì„¼í‹°ë¸Œ ë³€í™”ê°€ êµ­ë‚´ ì™„ì„±ì°¨ ìˆ˜ì¶œì— ë¯¸ì¹  ì˜í–¥ì€?",
            "ë°˜ë„ì²´ ê³µê¸‰ ì´ìŠˆê°€ 2025ë…„ ìë™ì°¨ ìƒì‚°ì— ì–´ë–¤ ë¦¬ìŠ¤í¬ê°€ ìˆë‚˜ìš”?",
        ],
    )

    with gr.Accordion("ì‹œìŠ¤í…œ/ëª¨ë¸ ì •ë³´", open=False):
        gr.Markdown(
            f"""
- ì‚¬ìš© ëª¨ë¸: **{MODEL_NAME}**  
- ë¡œì»¬ ì„œë²„: **http://localhost:11434** (Ollama ê¸°ë³¸)  
- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: `{SYSTEM_PROMPT}`  
- Temperature: `{TEMPERATURE}`  
- ê²€ìƒ‰: DuckDuckGo(ë‰´ìŠ¤, ì§€ì—­={DDG_REGION}, ê¸°ê°„={DDG_TIME})
"""
        )

if __name__ == "__main__":
    # ë‚´ë¶€ë§ë§Œ ì‚¬ìš©í•  ê²½ìš° share=False ê¶Œì¥
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)