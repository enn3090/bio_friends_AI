# ------------------------------------------------------------
# OpenAI API â†’ Ollama + DeepSeek-R1 ë³€í™˜ (Gradio UI ë²„ì „)
# ------------------------------------------------------------
# âœ… íŠ¹ì§•
#   - ë¡œì»¬ì— ì„¤ì¹˜ëœ Ollamaì˜ deepseek-r1 ëª¨ë¸ ì‚¬ìš© (API Key ë¶ˆí•„ìš”)
#   - Gradio ê¸°ë°˜ ëŒ€í™”í˜• UI ì œê³µ
#   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."
#   - temperature(ì°½ì˜ì„±) ì¡°ì ˆ ê°€ëŠ¥
# ------------------------------------------------------------
# ì¤€ë¹„ë¬¼
#   pip install gradio ollama
#   (Ollama ë° deepseek-r1 ëª¨ë¸ì€ ë¡œì»¬ì— ì„¤ì¹˜ë¼ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
#   ì˜ˆ) ëª¨ë¸ ì„¤ì¹˜:  ollama pull deepseek-r1
# ------------------------------------------------------------

import gradio as gr
import ollama

# -------------------------
# ì„¤ì •: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ & ì˜µì…˜
# -------------------------
SYSTEM_PROMPT = "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."
# Ollamaì˜ sampling ì˜µì…˜ (OpenAIì˜ temperatureì™€ ë™ì¼í•œ ê°œë…)
OLLAMA_OPTIONS = {
    "temperature": 0.9,  # ì°½ì˜ì„± ì •ë„ (0.0 ~ 2.0 ê¶Œì¥)
}

# -------------------------
# ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜
# -------------------------

def call_llm(messages):
    """
    Ollama deepseek-r1ì™€ ëŒ€í™”í•˜ì—¬ ë§ˆì§€ë§‰ assistant ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    messages: [{role: "system"|"user"|"assistant", content: str}, ...]
    """
    response = ollama.chat(
        model="deepseek-r1",
        messages=messages,
        options=OLLAMA_OPTIONS,
    )
    return response["message"]["content"]


# -------------------------
# Gradio ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# -------------------------

def on_submit(user_message, chat_history, msg_state):
    """
    - user_message: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ (str)
    - chat_history: Gradio Chatbotì— í‘œì‹œë˜ëŠ” [(user, bot), ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
    - msg_state: Ollamaì— ì „ë‹¬í•  ì „ì²´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ (system í¬í•¨)
    ë°˜í™˜ê°’: (ì—…ë°ì´íŠ¸ëœ chat_history, ì—…ë°ì´íŠ¸ëœ msg_state, ì…ë ¥ì°½ ì´ˆê¸°í™”)
    """
    if not user_message or user_message.strip() == "":
        # ê³µë°± ì…ë ¥ ë°©ì§€
        return gr.update(), msg_state, gr.update(value="")

    # ìµœì´ˆ í˜¸ì¶œ ì‹œ system ë©”ì‹œì§€ ì´ˆê¸°í™”
    if not msg_state:
        msg_state = [{"role": "system", "content": SYSTEM_PROMPT}]

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    msg_state.append({"role": "user", "content": user_message})

    # ëª¨ë¸ í˜¸ì¶œ
    assistant_text = call_llm(msg_state)

    # ëª¨ë¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì™€ ìƒíƒœì— ë°˜ì˜
    msg_state.append({"role": "assistant", "content": assistant_text})

    # Gradioì— í‘œì‹œë  ëŒ€í™” ëª©ë¡ì— ì¶”ê°€
    chat_history = chat_history + [(user_message, assistant_text)]

    # ì…ë ¥ì°½ ë¹„ìš°ê¸°
    return chat_history, msg_state, gr.update(value="")


def on_clear():
    """ëŒ€í™” ì „ì²´ ì´ˆê¸°í™” (í™”ë©´, ë‚´ë¶€ ìƒíƒœ ë‘˜ ë‹¤)"""
    empty_hist = []
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë§Œ ë‚¨ê¸´ ì´ˆê¸° ìƒíƒœë¡œ ë¦¬ì…‹í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ë³€ê²½í•˜ì„¸ìš”:
    # init_state = [{"role": "system", "content": SYSTEM_PROMPT}]
    init_state = []  # ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ë•Œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì…ë˜ë„ë¡ ë¹„ì›Œë‘ 
    return empty_hist, init_state


# -------------------------
# Gradio UI êµ¬ì„±
# -------------------------
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ§  DeepSeek-R1 ìƒë‹´ ì±—ë´‡ (ë¡œì»¬ Ollama)
    - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: **ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼.**
    - ëª¨ë¸: `deepseek-r1` (ë¡œì»¬)
    - ì˜µì…˜: `temperature=0.9`
    """)

    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="ìƒë‹´ ëŒ€í™”",
                type="messages",  # ë©”ì‹œì§€í˜• ë‚´ë¶€ êµ¬ì¡° ì‚¬ìš©
                height=480,
                avatar_images=(None, None),
            )
            with gr.Row():
                user_in = gr.Textbox(
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...",
                    show_label=False,
                    scale=5,
                )
                send_btn = gr.Button("ë³´ë‚´ê¸°", variant="primary")
                clear_btn = gr.Button("ì´ˆê¸°í™”", variant="secondary")
        with gr.Column(scale=2):
            gr.Markdown("""
            ### âš™ï¸ ì„¤ì •
            - **Temperature**ëŠ” í˜„ì¬ ì½”ë“œ ìƒìˆ˜ë¡œ 0.9ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
            - í•„ìš”ì‹œ `OLLAMA_OPTIONS`ë¥¼ ìˆ˜ì •í•´ ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ì˜µì…˜ì„ ì ìš©í•˜ì„¸ìš”.
            
            #### ì¶”ê°€ íŒ
            - ëª¨ë¸ êµì²´: `model="deepseek-r1"` â†’ `deepseek-r1:32b` ë“±
            - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½: `SYSTEM_PROMPT` ìˆ˜ì •
            - ìŠ¤íŠ¸ë¦¬ë°ì´ í•„ìš”í•˜ë‹¤ë©´ `ollama.chat` ëŒ€ì‹  `ollama.generate(stream=True, ...)` íŒ¨í„´ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)

    # ë‚´ë¶€ ìƒíƒœ: Ollamaì— ë³´ë‚¼ ì›ì‹œ ë©”ì‹œì§€ í˜•ì‹ ì €ì¥
    msg_state = gr.State([])  # [{role, content}, ...]

    # ì´ë²¤íŠ¸ ì—°ê²° (Enter ë° ë²„íŠ¼)
    user_in.submit(on_submit, [user_in, chatbot, msg_state], [chatbot, msg_state, user_in])
    send_btn.click(on_submit, [user_in, chatbot, msg_state], [chatbot, msg_state, user_in])

    # ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn.click(on_clear, outputs=[chatbot, msg_state])


# -------------------------
# ì•± ì‹¤í–‰
# -------------------------
if __name__ == "__main__":
    # ê³µìœ  í•„ìš” ì‹œ: demo.launch(share=True)
    demo.launch()