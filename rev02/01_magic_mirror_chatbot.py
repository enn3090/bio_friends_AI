import gradio as gr
import ollama

"""
ì—°ì† ëŒ€í™”(ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€) + Gradio UI + Ollama(DeepSeek-R1)
-----------------------------------------------------------------
- OpenAI API í‚¤(sk-...)ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¡œì»¬ì— ì„¤ì¹˜ëœ Ollama + deepseek-r1 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìê°€ ë³´ë‚¸ ì´ì „ ëŒ€í™”ë¥¼ ëª¨ë‘ ìœ ì§€í•˜ì—¬ ë¬¸ë§¥ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
- ì˜¨ë„(ì°½ì˜ì„±) ìŠ¬ë¼ì´ë” ì œê³µ.
- "ì´ˆê¸°í™”" ë²„íŠ¼ìœ¼ë¡œ íˆìŠ¤í† ë¦¬/ìƒíƒœë¥¼ ì™„ì „íˆ ë¦¬ì…‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ì „ ì¤€ë¹„(í„°ë¯¸ë„):
  1) Ollama ì„¤ì¹˜ í›„ ì‹¤í–‰
  2) deepseek-r1 ëª¨ë¸ ì¤€ë¹„:  `ollama pull deepseek-r1:latest`
  3) ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:        `python app.py`
"""

# ëŒ€í™”ì˜ ê¸°ë³¸ ì„±ê²©ì„ ê·œì •í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = (
    "ë„ˆëŠ” ë°±ì„¤ê³µì£¼ ì´ì•¼ê¸° ì†ì˜ ë§ˆë²• ê±°ìš¸ì´ì•¼. "
    "ê·¸ ì´ì•¼ê¸° ì†ì˜ ë§ˆë²• ê±°ìš¸ì˜ ìºë¦­í„°ì— ë¶€í•©í•˜ê²Œ, í’ˆìœ„ ìˆê³  ìš´ìœ¨ê° ìˆëŠ” ë§íˆ¬ë¡œ ë‹µë³€í•´ì¤˜."
)


def ensure_system(messages):
    """messages(list[dict])ì— system ì—­í•  í”„ë¡¬í”„íŠ¸ê°€ ì—†ë‹¤ë©´ ì‚½ì…í•©ë‹ˆë‹¤."""
    if not messages or messages[0].get("role") != "system":
        messages.insert(0, {"role": "system", "content": SYSTEM_PROMPT})
    return messages


def chat_with_mirror(user_input: str, history: list, state_messages: list, temperature: float):
    """
    - user_input: ì‚¬ìš©ìê°€ ë°©ê¸ˆ ì…ë ¥í•œ í…ìŠ¤íŠ¸
    - history: Gradio Chatbotì´ í™”ë©´ì— ë³´ì—¬ì¤„ (user, assistant) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    - state_messages: Ollamaë¡œ ë³´ë‚¼ ì›ì‹œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸(ì—­í• /ì½˜í…ì¸  ë”•ì…”ë„ˆë¦¬). ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥ìš©.
    - temperature: ì°½ì˜ì„± ì¡°ì ˆ ê°’

    ë°˜í™˜:
    - ì—…ë°ì´íŠ¸ëœ history(list[tuple])
    - ì—…ë°ì´íŠ¸ëœ state_messages(list[dict])
    """
    # 1) state_messagesì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³´ì¥
    state_messages = state_messages or []
    ensure_system(state_messages)

    # 2) ì‚¬ìš©ì ë°œí™” ì¶”ê°€
    state_messages.append({"role": "user", "content": user_input})

    # 3) Ollama + DeepSeek-R1 í˜¸ì¶œ
    #    (ì˜µì…˜ì— temperatureë¥¼ ì „ë‹¬í•´ ìƒì„± ì°½ì˜ì„± ì¡°ì ˆ)
    response = ollama.chat(
        model="deepseek-r1:latest",
        messages=state_messages,
        options={
            "temperature": float(temperature),
        },
    )

    assistant_text = response["message"]["content"]

    # 4) íˆìŠ¤í† ë¦¬(í™”ë©´ í‘œì‹œìš©)ì™€ state_messages(ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ìš©) ë™ê¸°í™”
    history = history + [(user_input, assistant_text)]
    state_messages.append({"role": "assistant", "content": assistant_text})

    return history, state_messages


def reset_history():
    """ëŒ€í™” ì´ˆê¸°í™”: í™”ë©´ íˆìŠ¤í† ë¦¬ì™€ ë‚´ë¶€ ìƒíƒœë¥¼ ëª¨ë‘ ë¹„ì›ë‹ˆë‹¤."""
    return [], []


with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    ## ğŸª ë§ˆë²• ê±°ìš¸ê³¼ì˜ ëŒ€í™” (ì—°ì† ëŒ€í™” ì§€ì›)
    ë°±ì„¤ê³µì£¼ ì´ì•¼ê¸° ì† *ë§ˆë²• ê±°ìš¸*ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì—¬ ë” ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ë‹µí•©ë‹ˆë‹¤.
    """)

    with gr.Row():
        temperature = gr.Slider(
            minimum=0.0,
            maximum=1.5,
            value=0.9,
            step=0.1,
            label="ì°½ì˜ì„±(Temperature)",
            info="ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€í•œ ë‹µë³€"
        )
        clear_btn = gr.Button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")

    chatbot = gr.Chatbot(
        label="ë§ˆë²• ê±°ìš¸",
        avatar_images=(None, None),
        bubble_full_width=False,
        height=480,
        show_copy_button=True,
         type='messages'
    )

    # state_messages: Ollamaë¡œ ë³´ë‚¼ ì›ì‹œ ë©”ì‹œì§€(ì—­í• /ì½˜í…ì¸ ) ì €ì¥ì†Œ
    state_messages = gr.State([])

    user_box = gr.Textbox(
        placeholder="ê±°ìš¸ì•„ ê±°ìš¸ì•„, ì„¸ìƒì—ì„œ ëˆ„ê°€ ì œì¼ ì•„ë¦„ë‹µë‹ˆ?",
        label="ì§ˆë¬¸ ì…ë ¥",
        lines=2,
    )

    # ì œì¶œ ë™ì‘: user_box -> ëª¨ë¸ í˜¸ì¶œ -> chatbot/ìƒíƒœ ê°±ì‹ 
    def on_submit(user_input, chat_hist, state_msgs, temp):
        # ë¹ˆ ì…ë ¥ì€ ë¬´ì‹œ
        if not user_input or not user_input.strip():
            return gr.update(), state_msgs
        new_hist, new_state = chat_with_mirror(user_input.strip(), chat_hist, state_msgs, temp)
        return new_hist, new_state

    user_box.submit(
        fn=on_submit,
        inputs=[user_box, chatbot, state_messages, temperature],
        outputs=[chatbot, state_messages]
    ).then(
        lambda: gr.update(value=""),
        None,
        user_box
    )

    # ì´ˆê¸°í™” ë²„íŠ¼: íˆìŠ¤í† ë¦¬/ìƒíƒœ ëª¨ë‘ ì´ˆê¸°í™”
    clear_btn.click(
        fn=reset_history,
        inputs=None,
        outputs=[chatbot, state_messages]
    )

    gr.Markdown(
        """
        **TIP**: ë” ê¸¸ê²Œ ì´ì–´ì§€ëŠ” ëŒ€í™”ë¥¼ ì›í•˜ë©´ ì§ˆë¬¸ì„ ì§§ê²Œ ì—¬ëŸ¬ ë²ˆ ë˜ì ¸ë³´ì„¸ìš”. 
        ëª¨ë¸ì´ ì´ì „ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ ì‘ë‹µ í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤.
        """
    )

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()
