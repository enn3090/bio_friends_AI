# -*- coding: utf-8 -*-
"""
pip install camelot-py[cv] tabula-py pdfplumber pandas openpyxl

PDFì˜ í‘œë¥¼ ì—‘ì…€/CSVë¡œ êµ¬ì¡°ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸

âœ”ï¸ ì „ëµ
1) Camelot (lattice â†’ stream ìˆœ)ìœ¼ë¡œ í˜ì´ì§€ë³„ í‘œ ê°ì§€/ì¶”ì¶œ
2) ë³´ì¡°ë¡œ Tabulaë„ ì‹œë„ (lattice/stream)
3) í•„ìš”ì‹œ OCR(ocrmypdf)ë¡œ ê°€ì§œ í…ìŠ¤íŠ¸ ë¶€ì—¬ í›„ ë‹¤ì‹œ 1)~2) ì‹œë„ (ì˜µì…˜)

âš™ï¸ ì‚¬ì „ ì¤€ë¹„
- pip install camelot-py[cv] tabula-py pdfplumber pandas openpyxl
- ì‹œìŠ¤í…œ ì˜ì¡´ì„±: Java(íƒ­ë£°ë¼), Ghostscript(ì¼ë¶€ í™˜ê²½ì—ì„œ í•„ìš”), poppler(OpenCV/ë Œë”ë§ ë³´ì¡°)
- OCR ì‚¬ìš© ì‹œ: ocrmypdf ì„¤ì¹˜ í•„ìš” (ì˜ˆ: brew install ocrmypdf ë˜ëŠ” apt-get install ocrmypdf)

ğŸ’¾ ì¶œë ¥
- output_dir/
  â”œâ”€ tables/ (í˜ì´ì§€ë³„-í…Œì´ë¸”ë³„ CSV ì €ì¥)
  â”œâ”€ all_tables.xlsx (ëª¨ë“  í‘œë¥¼ í•œ íŒŒì¼ë¡œ, ì‹œíŠ¸: p{page}_t{idx})
  â””â”€ extract_report.json (ë¬´ì—‡ì„ ëª‡ ê°œ ì¶”ì¶œí–ˆëŠ”ì§€ ìš”ì•½)

ì°¸ê³ : ìŠ¤ìº” PDF(ì´ë¯¸ì§€ ê¸°ë°˜)ëŠ” OCR ì˜µì…˜ì„ ì¼œì•¼ ì¸ì‹ë¥ ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤.
"""

import os
import json
import subprocess
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd
import camelot
import tabula
import pdfplumber


def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def is_scanned_pdf(pdf_path: Path, sample_pages: int = 3) -> bool:
    """í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ëŠ”(=ìŠ¤ìº” ê°€ëŠ¥ì„±ì´ ë†’ì€) PDFì¸ì§€ ëŒ€ëµ íŒë‹¨.
    ì•ìª½ ì¼ë¶€ í˜ì´ì§€ë§Œ ìƒ˜í”Œë§í•´ í…ìŠ¤íŠ¸ ìœ ë¬´ ê²€ì‚¬.
    """
    try:
        with pdfplumber.open(str(pdf_path)) as pdf:
            n = min(sample_pages, len(pdf.pages))
            for i in range(n):
                txt = pdf.pages[i].extract_text() or ""
                if txt.strip():
                    return False
        return True
    except Exception:
        # ì—´ê¸° ì‹¤íŒ¨ ì‹œ ìŠ¤ìº” ê°€ëŠ¥ì„± ë†’ë‹¤ê³  ê°€ì • (ë³´ìˆ˜ì ìœ¼ë¡œ True)
        return True


def run_ocr_if_needed(pdf_path: Path, ocr: bool) -> Path:
    """ocr=Trueë©´ ocrmypdfë¡œ ê°•ì œ OCR PDF ìƒì„± í›„ ê²½ë¡œ ë°˜í™˜. ì•„ë‹ˆë©´ ì›ë³¸ ê²½ë¡œ ë°˜í™˜."""
    if not ocr:
        return pdf_path

    ocr_out = pdf_path.with_suffix("")
    ocr_out = ocr_out.parent / f"{pdf_path.stem}_ocr.pdf"

    try:
        subprocess.run([
            "ocrmypdf", "--skip-text", "--force-ocr", "--quiet",
            str(pdf_path), str(ocr_out)
        ], check=True)
        return ocr_out
    except FileNotFoundError:
        print("[ê²½ê³ ] ocrmypdf ë¯¸ì„¤ì¹˜ë¡œ OCR ë‹¨ê³„ ê±´ë„ˆëœë‹ˆë‹¤. (brew/aptë¡œ ì„¤ì¹˜ ê°€ëŠ¥)")
        return pdf_path
    except subprocess.CalledProcessError as e:
        print(f"[ê²½ê³ ] ocrmypdf ì‹¤í–‰ ì‹¤íŒ¨: {e}\nì›ë³¸ PDFë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        return pdf_path


def camelot_try(pdf_path: Path, pages: str, flavor: str, strip_text: str = "\n") -> List[pd.DataFrame]:
    """Camelotìœ¼ë¡œ í‘œ ì¶”ì¶œ ì‹œë„ í›„ DataFrame ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    try:
        tables = camelot.read_pdf(str(pdf_path), pages=pages, flavor=flavor, strip_text=strip_text)
        return [t.df for t in tables]
    except Exception as e:
        print(f"[ì •ë³´] Camelot {flavor} ì‹œë„ ì‹¤íŒ¨: {e}")
        return []


def tabula_try(pdf_path: Path, pages: str, lattice: bool) -> List[pd.DataFrame]:
    """Tabulaë¡œ í‘œ ì¶”ì¶œ ì‹œë„ í›„ DataFrame ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    try:
        dfs = tabula.read_pdf(str(pdf_path), pages=pages, lattice=lattice, multiple_tables=True, stream=not lattice)
        return dfs or []
    except Exception as e:
        print(f"[ì •ë³´] Tabula {('lattice' if lattice else 'stream')} ì‹œë„ ì‹¤íŒ¨: {e}")
        return []


def extract_tables(pdf_path: str, output_dir: str, ocr: bool = False) -> Dict[str, Any]:
    pdf_path = Path(pdf_path)
    output_dir = Path(output_dir)

    ensure_dir(output_dir)
    tables_dir = output_dir / "tables"
    ensure_dir(tables_dir)

    # 0) ìŠ¤ìº” ì—¬ë¶€ íŒë‹¨ í›„, OCR ì˜µì…˜ì´ ì¼œì ¸ ìˆìœ¼ë©´ ì„  OCR
    scanned_guess = is_scanned_pdf(pdf_path)
    working_pdf = run_ocr_if_needed(pdf_path, ocr and scanned_guess)

    # í˜ì´ì§€ ìˆ˜ ê³„ì‚°(ë³´ê³ ìš©)
    try:
        with pdfplumber.open(str(working_pdf)) as pdf:
            total_pages = len(pdf.pages)
    except Exception:
        total_pages = None

    all_tables: List[Dict[str, Any]] = []

    # 1) Camelot lattice â†’ stream ìˆœìœ¼ë¡œ ì „ì²´ í˜ì´ì§€ ì‹œë„
    pages_param = "all"
    for method in [
        ("camelot", "lattice"),
        ("camelot", "stream"),
        ("tabula", "lattice"),
        ("tabula", "stream"),
    ]:
        engine, mode = method
        dfs: List[pd.DataFrame] = []

        if engine == "camelot":
            dfs = camelot_try(working_pdf, pages_param, mode)
        else:
            dfs = tabula_try(working_pdf, pages_param, lattice=(mode == "lattice"))

        if dfs:
            # ì¶”ì¶œ ì„±ê³µ ì‹œ ë°”ë¡œ ì •ë¦¬ ì €ì¥ í›„ ì¢…ë£Œ
            idx = 0
            excel_path = output_dir / "all_tables.xlsx"
            with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
                for df in dfs:
                    idx += 1
                    # ê³µë°± í–‰/ì—´ ì •ë¦¬(ê°„ë‹¨ ì „ì²˜ë¦¬)
                    df = df.replace({"\u00a0": " "}, regex=True)
                    df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)

                    csv_name = f"tables_pall_t{idx}_{engine}_{mode}.csv"
                    csv_path = tables_dir / csv_name
                    df.to_csv(csv_path, index=False)

                    sheet_name = f"pALL_t{idx}_{engine[:1]}{mode[:1]}"
                    df.to_excel(writer, sheet_name=sheet_name, index=False)

                    all_tables.append({
                        "page": "all",
                        "index": idx,
                        "engine": engine,
                        "mode": mode,
                        "csv": str(csv_path),
                        "sheet": sheet_name,
                        "rows": int(df.shape[0]),
                        "cols": int(df.shape[1]),
                    })
            break  # ì–´ë–¤ ì—”ì§„/ëª¨ë“œë¡œë“  í•œ ë²ˆ ì„±ê³µí•˜ë©´ ì¢…ë£Œ (í•„ìš”ì‹œ ì œê±° ê°€ëŠ¥)

    # 2) ì—”ì§„ ì¼ê´„ ì‹œë„ì—ì„œ ì‹¤íŒ¨í–ˆë‹¤ë©´, í˜ì´ì§€ë³„ ì„¸ë°€ ì‹œë„
    if not all_tables:
        print("[ì •ë³´] ì „ì²´ í˜ì´ì§€ ì¼ê´„ ì¶”ì¶œ ì‹¤íŒ¨ â†’ í˜ì´ì§€ë³„ ì„¸ë°€ ì¶”ì¶œ ì‹œë„")
        # ì„¸ë°€ ì‹œë„: ê° í˜ì´ì§€ë§ˆë‹¤ lattice â†’ stream (camelot, tabula)
        try:
            with pdfplumber.open(str(working_pdf)) as pdf:
                total_pages = len(pdf.pages)
        except Exception:
            total_pages = 1

        excel_path = output_dir / "all_tables.xlsx"
        with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
            table_counter = 0
            for p in range(1, (total_pages or 1) + 1):
                page_str = str(p)
                for engine, mode in [("camelot", "lattice"), ("camelot", "stream"), ("tabula", "lattice"), ("tabula", "stream")]:
                    if engine == "camelot":
                        dfs = camelot_try(working_pdf, page_str, mode)
                    else:
                        dfs = tabula_try(working_pdf, page_str, lattice=(mode == "lattice"))

                    if not dfs:
                        continue

                    for df in dfs:
                        table_counter += 1
                        df = df.replace({"\u00a0": " "}, regex=True)
                        df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)

                        csv_name = f"tables_p{p}_t{table_counter}_{engine}_{mode}.csv"
                        csv_path = tables_dir / csv_name
                        df.to_csv(csv_path, index=False)

                        sheet_name = f"p{p}_t{table_counter}_{engine[:1]}{mode[:1]}"
                        # ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ(ì—‘ì…€ 31ì) ì²˜ë¦¬
                        if len(sheet_name) > 31:
                            sheet_name = sheet_name[:31]
                        df.to_excel(writer, sheet_name=sheet_name, index=False)

                        all_tables.append({
                            "page": p,
                            "index": table_counter,
                            "engine": engine,
                            "mode": mode,
                            "csv": str(csv_path),
                            "sheet": sheet_name,
                            "rows": int(df.shape[0]),
                            "cols": int(df.shape[1]),
                        })

    # 3) ë¦¬í¬íŠ¸ ì €ì¥
    report = {
        "pdf": str(pdf_path),
        "working_pdf": str(working_pdf),
        "total_pages": total_pages,
        "scanned_guess": bool(scanned_guess),
        "tables_found": len(all_tables),
        "details": all_tables,
    }
    with open(output_dir / "extract_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"âœ… í‘œ ì¶”ì¶œ ì™„ë£Œ â€” ì´ {len(all_tables)}ê°œ. ê²°ê³¼: {output_dir}")
    if not all_tables:
        print("âš ï¸ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFì¼ ê²½ìš° ocr=Trueë¡œ ì¬ì‹œë„í•˜ê±°ë‚˜, í…Œì´ë¸” ì„ /ì¹¸ì´ ë¶„ëª…í•œ ê³ í™”ì§ˆ PDFë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
    return report


if __name__ == "__main__":
    # ì˜ˆì‹œ ê²½ë¡œ â€” ì‚¬ìš©ì íŒŒì¼ëª…ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
    pdf_file_path = "chap04/data/ê³¼ì •ê¸°ë°˜ ì‘ë¬¼ëª¨í˜•ì„ ì´ìš©í•œ ì›¹ ê¸°ë°˜ ë°€ ì¬ë°°ê´€ë¦¬ ì˜ì‚¬ê²°ì • ì§€ì›ì‹œìŠ¤í…œ ì„¤ê³„ ë° êµ¬ì¶•.pdf"
    out_dir = "chap04/output_tables"

    # ìŠ¤ìº” PDFë¼ë©´ ocr=True ê¶Œì¥
    report = extract_tables(pdf_file_path, out_dir, ocr=True)
    # print(json.dumps(report, ensure_ascii=False, indent=2))
