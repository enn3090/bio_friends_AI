"""
[OpenCode ë³€í™˜ë³¸]

ëª©í‘œ: LangChain + OpenAI(Closed LLM, ChatOpenAI) ì½˜ì†” ì•±ì„
â†’ **ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ LLM (Ollamaì˜ DeepSeek-R1)** + **Gradio UI**ë¡œ ë³€í™˜

í•µì‹¬ ë³€ê²½ì 
1) API Key, OpenAI ì˜ì¡´ ì œê±° (ë¡œì»¬ Ollama ì„œë²„ ì‚¬ìš©: http://localhost:11434)
2) ëª¨ë¸: deepseek-r1 (ì˜ˆ: "deepseek-r1:latest" ë˜ëŠ” "deepseek-r1:7b")
3) ì½˜ì†” while-loop â†’ **Gradio ChatInterface** ì±„íŒ… UI
4) LangChain í˜¸í™˜: ChatOllama ì‚¬ìš©, System/Human/AI ë©”ì‹œì§€ ìœ ì§€
5) DeepSeek-R1ì´ ìƒì„±í•˜ëŠ” <think> ë‚´ë¶€ ì‚¬ê³  í…ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ìì—ê²Œ ìˆ¨ê¹€

ì‚¬ì „ ì¤€ë¹„
- Ollama ì„¤ì¹˜: https://ollama.com
- ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: í„°ë¯¸ë„ì—ì„œ `ollama pull deepseek-r1:latest`
- íŒŒì´ì¬ íŒ¨í‚¤ì§€:
  pip install gradio langchain langchain-community ollama

ì‹¤í–‰
- `python app.py` ì‹¤í–‰ í›„ ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:7860
"""

from typing import List, Tuple
import re

import gradio as gr

# LangChain ë©”ì‹œì§€ íƒ€ì… (ì› ì½”ë“œì™€ ë™ì¼ ì¸í„°í˜ì´ìŠ¤)
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# LangChainìš© Ollama ì±„íŒ… ëª¨ë¸
# ìµœì‹  ë²„ì „ì—ì„œëŠ” `langchain_ollama` íŒ¨í‚¤ì§€ë„ ìˆìŠµë‹ˆë‹¤.
# ì—¬ê¸°ì„œëŠ” í˜¸í™˜ì„± ì¢‹ì€ ì»¤ë®¤ë‹ˆí‹° ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from langchain_community.chat_models import ChatOllama

# ===== ì„¤ì • =====
MODEL_NAME = "deepseek-r1:latest"  # í•„ìš” ì‹œ "deepseek-r1:7b" ë“±ìœ¼ë¡œ êµì²´
SYSTEM_PROMPT = "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."
TEMPERATURE = 0.9  # OpenAI ì˜ˆì‹œ ì½”ë“œì˜ temperatureì— ëŒ€ì‘

# DeepSeek-R1ì˜ ë‚´ë¶€ ì‚¬ê³ ë¥¼ ê°ì‹¼ <think>...</think> ì œê±°ìš© íŒ¨í„´
THINK_TAG_PATTERN = re.compile(r"<think>.*?</think>", re.DOTALL)


def strip_think(text: str) -> str:
    """DeepSeek-R1ì´ ì¶œë ¥í•˜ëŠ” ë‚´ë¶€ ì‚¬ê³  ë‚´ìš©ì„ ì œê±°í•´ ì‚¬ìš©ìì—ê²ŒëŠ” ë³´ì´ì§€ ì•Šë„ë¡ í•¨."""
    return THINK_TAG_PATTERN.sub("", text).strip()


# LangChain ChatOllama ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# - Ollama ë¡œì»¬ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤: `ollama serve`
llm = ChatOllama(
    model=MODEL_NAME,
    temperature=TEMPERATURE,
    # base_url="http://localhost:11434",  # ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ ì£¼ì„ ê°€ëŠ¥
)


def history_to_messages(history: List[Tuple[str, str]]) -> List:
    """
    Gradio ChatInterfaceì˜ history([[user, assistant], ...])ë¥¼
    LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    """
    msgs: List = [SystemMessage(SYSTEM_PROMPT)]
    for u, a in history:
        if u:
            msgs.append(HumanMessage(u))
        if a:
            msgs.append(AIMessage(a))
    return msgs


def respond(user_input: str, history: List[Tuple[str, str]]) -> str:
    """
    ChatInterface ì½œë°±:
    - ê¸°ì¡´ íˆìŠ¤í† ë¦¬ + ì‚¬ìš©ì ì…ë ¥ì„ LangChain ë©”ì‹œì§€ë¡œ êµ¬ì„±í•´ ëª¨ë¸ í˜¸ì¶œ
    - DeepSeekì˜ <think> ì„¹ì…˜ì€ ì œê±° í›„ ë°˜í™˜
    """
    messages = history_to_messages(history)
    messages.append(HumanMessage(user_input))

    # LangChain ChatOllamaëŠ” .invokeë¡œ ë™ê¸° í˜¸ì¶œ
    ai_msg = llm.invoke(messages)
    content = getattr(ai_msg, "content", str(ai_msg))
    return strip_think(content)


# ===== Gradio UI êµ¬ì„± =====
with gr.Blocks(css="footer {visibility: hidden}") as demo:
    gr.Markdown("## ğŸ’¬ Chatbot (DeepSeek-R1 on Ollama + Gradio + LangChain)")

    chat_ui = gr.ChatInterface(
        fn=respond,
        chatbot=gr.Chatbot(
            label="ìƒë‹´ì‚¬",
            height=520,
        ),
        title="",
        description=(
            "ë¡œì»¬ **Ollama**ì˜ **DeepSeek-R1** ëª¨ë¸ì„ LangChainìœ¼ë¡œ êµ¬ë™í•©ë‹ˆë‹¤. "
            "ì¢Œì¸¡ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì ê³  ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë³´ì„¸ìš”."
        ),
        theme="soft",
        retry_btn="ë‹¤ì‹œ ìƒì„±",
        undo_btn="ì´ì „ ë©”ì‹œì§€ ì‚­ì œ",
        clear_btn="ëŒ€í™” ì´ˆê¸°í™”",
        examples=[
            "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢€ ìš°ìš¸í•´ìš”.",
            "ë©´ì ‘ì´ ê±±ì •ë¼ìš”. ì¤€ë¹„ íŒì´ ìˆì„ê¹Œìš”?",
            "í•™ìŠµ/ì—…ë¬´ ë£¨í‹´ì„ ì¡ê³  ì‹¶ì€ë° ë„ì™€ì¤˜.",
        ],
    )

    with gr.Accordion("ì‹œìŠ¤í…œ/ëª¨ë¸ ì •ë³´", open=False):
        gr.Markdown(
            f"""
- ì‚¬ìš© ëª¨ë¸: **{MODEL_NAME}**  
- ë¡œì»¬ ì„œë²„: **http://localhost:11434** (Ollama ê¸°ë³¸)  
- í”„ë¡¬í”„íŠ¸ ì—­í• : `{SYSTEM_PROMPT}`  
- Temperature: `{TEMPERATURE}`
"""
        )

if __name__ == "__main__":
    # ë‚´ë¶€ë§ë§Œ ì‚¬ìš©í•  ê²½ìš° share=False ìœ ì§€
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)

