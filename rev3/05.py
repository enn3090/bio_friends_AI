# ------------------------------------------------------------
# OpenAI API ì½”ë“œ â†’ Ollama + DeepSeek-R1 ë³€í™˜ ì˜ˆì œ
# ------------------------------------------------------------
# âœ… ì£¼ìš” ë³€ê²½ì :
#   1. OpenAI API Key ì œê±° â†’ ë¡œì»¬ Ollama ëª¨ë¸ ì‚¬ìš©
#   2. ëª¨ë¸ëª…: "deepseek-r1" (ë¡œì»¬ PCì— ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
#   3. í„°ë¯¸ë„ì—ì„œ ì…ë ¥/ì¶œë ¥ ë°©ì‹ ìœ ì§€ (ì›ë˜ ì½”ë“œì™€ ë™ì¼)
# ------------------------------------------------------------

import ollama  # Ollama ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install ollama)

# â‘ 
def get_ai_response(messages):
    """
    Ollamaë¥¼ í†µí•´ DeepSeek-R1 ëª¨ë¸ê³¼ ëŒ€í™”í•˜ê³ ,
    ê°€ì¥ ìµœì‹  ì‘ë‹µ ë‚´ìš©ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    response = ollama.chat(
        model="deepseek-r1",
        messages=messages  # ì „ì²´ ëŒ€í™” ê¸°ë¡ ì „ë‹¬
    )
    return response["message"]["content"]  # ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜


# ì´ˆê¸° ëŒ€í™” ì„¤ì •
messages = [
    {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
]

# ëŒ€í™” ë£¨í”„
while True:
    user_input = input("ì‚¬ìš©ì: ")

    if user_input.lower() == "exit":  # â‘¡ ì¢…ë£Œ ì¡°ê±´
        print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")
        break

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€
    messages.append({"role": "user", "content": user_input})

    # ëª¨ë¸ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
    ai_response = get_ai_response(messages)

    # AI ì‘ë‹µë„ ê¸°ë¡ì— ì¶”ê°€
    messages.append({"role": "assistant", "content": ai_response})

    # ê²°ê³¼ ì¶œë ¥
    print("AI:", ai_response)